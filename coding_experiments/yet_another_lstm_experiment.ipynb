{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_time_series_for_window(start_date, end_date, station, dataframe):\n",
    "    return dataframe.loc[start_date:end_date, [station]]\n",
    "\n",
    "\n",
    "def check_nan_values(dataframe):\n",
    "    return dataframe.isnull().values.any()\n",
    "\n",
    "\n",
    "def get_valid_sequences(df):\n",
    "    valid_sequences = []\n",
    "    starting_idx = 0\n",
    "\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        flow = row[0]\n",
    "\n",
    "        if np.isnan(flow):\n",
    "\n",
    "            if starting_idx < i-1:\n",
    "                valid_sequences.append((starting_idx, i))\n",
    "                starting_idx = i+1\n",
    "            else:\n",
    "                starting_idx = i+1\n",
    "                continue\n",
    "    \n",
    "    if not check_nan_values(df.iloc[starting_idx:, :]):\n",
    "        valid_sequences.append((starting_idx, len(df)))\n",
    "    return valid_sequences\n",
    "\n",
    "\n",
    "def valid_seqs_minimum_len(valid_seqs, seq_len):\n",
    "    \n",
    "    valid_seqs_min_len = []\n",
    "    pops = []\n",
    "    for i, (start, end) in enumerate(valid_seqs):\n",
    "        if end - start >= seq_len:\n",
    "            valid_seqs_min_len.append((start, end))\n",
    "\n",
    "    return valid_seqs_min_len\n",
    "\n",
    "\n",
    "\n",
    "def split_sequences(possible_seqs, split_len):\n",
    "    \n",
    "    usable_seqs = []\n",
    "    for seq in possible_seqs:\n",
    "        usable_seqs += get_seq_splits(seq, split_len)\n",
    "        \n",
    "    return usable_seqs\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_seq_splits(seq, split_len):\n",
    "    \n",
    "    start = seq[0]\n",
    "    end = seq[1]\n",
    "    \n",
    "    chunks = (end - start) // (split_len+1)     # +1 because there must be an unobserved item after each chunk\n",
    "                                                # which will be the y (after window value)\n",
    "\n",
    "    splits = []\n",
    "    prev_end_chunk = start\n",
    "    for i in range(chunks):\n",
    "\n",
    "        start_chunk = prev_end_chunk\n",
    "        end_chunk = start_chunk + split_len\n",
    "        splits.append((start_chunk, end_chunk))\n",
    "        prev_end_chunk = end_chunk+1\n",
    "        \n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_seq_obs_values(seq, df):\n",
    "    return np.array(df.iloc[seq[0]:seq[1], :]), np.array(df.iloc[seq[1], :])\n",
    "\n",
    "\n",
    "def split_seqs_train_test(train_frac, usable_seqs):\n",
    "    \n",
    "    total_seqs = len(usable_seqs)\n",
    "    train_amount = round(total_seqs * train_frac)\n",
    "    \n",
    "    random.shuffle(usable_seqs)\n",
    "    train_seqs = usable_seqs[0:train_amount]\n",
    "    test_seqs = usable_seqs[train_amount:]\n",
    "    \n",
    "    return train_seqs, test_seqs\n",
    "\n",
    "\n",
    "def mount_trainable_testable_arrays(seqs, df):\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for seq in seqs:\n",
    "        x, y = get_seq_obs_values(seq, df)\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    \n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "\n",
    "\n",
    "def transform_cleb_df_into_wal_df(cleb_df):\n",
    "    \n",
    "    index_names = {}\n",
    "    for i, (_, row) in enumerate(cleb_df.iterrows()):\n",
    "        \n",
    "        year = str(int(row[2]))\n",
    "        month = str(int(row[1]))\n",
    "        day = str(int(row[0]))\n",
    "        hour = str(int(row[3]))\n",
    "        index_name = year+'-'+month+'-'+day+'-'+hour\n",
    "        \n",
    "        index_names[i] = index_name\n",
    "        \n",
    "    \n",
    "    cleb_df.rename(index=index_names)\n",
    "    cleb_df = cleb_df.drop('day', 1)\n",
    "    cleb_df = cleb_df.drop('month', 1)\n",
    "    cleb_df = cleb_df.drop('year', 1)\n",
    "    cleb_df = cleb_df.drop('hour', 1)\n",
    "    return cleb_df.replace(-1, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow_path = \"/home/colombelli/Documents/hydro-ml/data/Vazao.txt\"\n",
    "rain_path = \"/home/colombelli/Documents/hydro-ml/data/Chuva.txt\"\n",
    "et_path = \"/home/colombelli/Documents/hydro-ml/data/ET.txt\"\n",
    "\n",
    "flow_df = pd.read_csv(flow_path, sep=\"\\t\", header=None)\n",
    "flow_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"flow\"]\n",
    "\n",
    "rain_df = pd.read_csv(rain_path, sep=\"\\t\", header=None)\n",
    "rain_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"rain\"]\n",
    "\n",
    "et_df = pd.read_csv(et_path, sep=\"\\t\", header=None)\n",
    "et_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"et\"]\n",
    "\n",
    "\n",
    "flow_df = transform_cleb_df_into_wal_df(flow_df)\n",
    "rain_df = transform_cleb_df_into_wal_df(rain_df)\n",
    "et_df = transform_cleb_df_into_wal_df(et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([flow_df, rain_df, et_df, flow_df], axis=1)\n",
    "dataset.columns = ['flow', 'rain', 'et', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this fixed val_seq was extracted from the other notebook (no complete automation yet - just a poc)\n",
    "val_seq = [(5962, 6051), (6078, 17486), (17487, 18718), (18741, 23437)]\n",
    "\n",
    "#n_steps_in = 24*30   #24 hours, 30 days\n",
    "#n_steps_out = 24*7   #24 hours, 7 days\n",
    "n_steps_in = 3 \n",
    "n_steps_out = 24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_split = np.array(dataset.iloc[6078:17486, ])\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, \n",
    "               activation='sigmoid', \n",
    "               input_shape=(n_steps_in, n_features)))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 282374.1875\n",
      "Epoch 2/200\n",
      "356/356 [==============================] - 6s 15ms/step - loss: 248343.9688\n",
      "Epoch 3/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 222445.9375\n",
      "Epoch 4/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 201566.3125\n",
      "Epoch 5/200\n",
      "356/356 [==============================] - 5s 15ms/step - loss: 183766.6250\n",
      "Epoch 6/200\n",
      "356/356 [==============================] - 5s 15ms/step - loss: 168760.3750\n",
      "Epoch 7/200\n",
      "356/356 [==============================] - 5s 15ms/step - loss: 155982.2188\n",
      "Epoch 8/200\n",
      "356/356 [==============================] - 5s 15ms/step - loss: 144853.4062\n",
      "Epoch 9/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 135072.5938\n",
      "Epoch 10/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 126287.6875\n",
      "Epoch 11/200\n",
      "356/356 [==============================] - 6s 17ms/step - loss: 118173.6641\n",
      "Epoch 12/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 110570.5547\n",
      "Epoch 13/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 103395.3438\n",
      "Epoch 14/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 96606.0000\n",
      "Epoch 15/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 90191.1406\n",
      "Epoch 16/200\n",
      "356/356 [==============================] - 6s 16ms/step - loss: 84262.3125\n",
      "Epoch 17/200\n",
      "356/356 [==============================] - 5s 14ms/step - loss: 78675.3906\n",
      "Epoch 18/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 73519.9062\n",
      "Epoch 19/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 68713.0000\n",
      "Epoch 20/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 64257.0469\n",
      "Epoch 21/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 60188.8516\n",
      "Epoch 22/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 56370.4648\n",
      "Epoch 23/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 52663.8867\n",
      "Epoch 24/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 49488.4258\n",
      "Epoch 25/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 46405.6016\n",
      "Epoch 26/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 43504.6211\n",
      "Epoch 27/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 40941.0312\n",
      "Epoch 28/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 38415.1367\n",
      "Epoch 29/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 36326.5625\n",
      "Epoch 30/200\n",
      "356/356 [==============================] - 4s 11ms/step - loss: 34695.7344\n",
      "Epoch 31/200\n",
      "356/356 [==============================] - 4s 11ms/step - loss: 33068.4414\n",
      "Epoch 32/200\n",
      "356/356 [==============================] - 4s 11ms/step - loss: 31297.5625\n",
      "Epoch 33/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 29737.1094\n",
      "Epoch 34/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 28357.8457\n",
      "Epoch 35/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 27049.6777\n",
      "Epoch 36/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 26845.7246\n",
      "Epoch 37/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 25796.4902\n",
      "Epoch 38/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 24548.9141\n",
      "Epoch 39/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 23849.8730\n",
      "Epoch 40/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 22847.5586\n",
      "Epoch 41/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 22346.1816\n",
      "Epoch 42/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 21510.5273\n",
      "Epoch 43/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 20548.5820\n",
      "Epoch 44/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 20544.0332\n",
      "Epoch 45/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 19893.7695\n",
      "Epoch 46/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 18949.4531\n",
      "Epoch 47/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 18020.4922\n",
      "Epoch 48/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 17550.9941\n",
      "Epoch 49/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 17247.2754\n",
      "Epoch 50/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 16872.9805\n",
      "Epoch 51/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16870.5039\n",
      "Epoch 52/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16836.4180\n",
      "Epoch 53/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16635.2148\n",
      "Epoch 54/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 16421.3848\n",
      "Epoch 55/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 16258.3770\n",
      "Epoch 56/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 16688.4121\n",
      "Epoch 57/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16149.4688\n",
      "Epoch 58/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16233.3623\n",
      "Epoch 59/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15923.6377\n",
      "Epoch 60/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 15790.6895\n",
      "Epoch 61/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15747.5410\n",
      "Epoch 62/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 15953.8164\n",
      "Epoch 63/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16498.3555\n",
      "Epoch 64/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16161.7490\n",
      "Epoch 65/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15927.7510\n",
      "Epoch 66/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 16085.0645\n",
      "Epoch 67/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15933.0088\n",
      "Epoch 68/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15014.1836\n",
      "Epoch 69/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15321.3701\n",
      "Epoch 70/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15257.4775\n",
      "Epoch 71/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14781.1699\n",
      "Epoch 72/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 15608.2617\n",
      "Epoch 73/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 15364.5361\n",
      "Epoch 74/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 15179.9346\n",
      "Epoch 75/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 15098.6895\n",
      "Epoch 76/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 14902.3945\n",
      "Epoch 77/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14832.2666\n",
      "Epoch 78/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15084.5488\n",
      "Epoch 79/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 15342.8965\n",
      "Epoch 80/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 15205.8467\n",
      "Epoch 81/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 15446.3467\n",
      "Epoch 82/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 15075.3291\n",
      "Epoch 83/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14585.6670\n",
      "Epoch 84/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14895.5205\n",
      "Epoch 85/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14933.7930\n",
      "Epoch 86/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15055.6631\n",
      "Epoch 87/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14595.7617\n",
      "Epoch 88/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15233.6445\n",
      "Epoch 89/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15261.9756\n",
      "Epoch 90/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 15296.5332\n",
      "Epoch 91/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 15166.4873\n",
      "Epoch 92/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14944.7578\n",
      "Epoch 93/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14898.5996\n",
      "Epoch 94/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 3s 9ms/step - loss: 14860.2510\n",
      "Epoch 95/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14842.4844\n",
      "Epoch 96/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14839.9160\n",
      "Epoch 97/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14468.6152\n",
      "Epoch 98/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14036.1465\n",
      "Epoch 99/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14386.5869\n",
      "Epoch 100/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14580.5928\n",
      "Epoch 101/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 14701.8828\n",
      "Epoch 102/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14793.1836\n",
      "Epoch 103/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14548.2998\n",
      "Epoch 104/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14332.9551\n",
      "Epoch 105/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14165.7012\n",
      "Epoch 106/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14353.7754\n",
      "Epoch 107/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14463.7344\n",
      "Epoch 108/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14009.5381\n",
      "Epoch 109/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14199.1465\n",
      "Epoch 110/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14514.4912\n",
      "Epoch 111/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14263.3242\n",
      "Epoch 112/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14278.2246\n",
      "Epoch 113/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14092.1064\n",
      "Epoch 114/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14124.1045\n",
      "Epoch 115/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14335.4180\n",
      "Epoch 116/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13974.5566\n",
      "Epoch 117/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14583.5723\n",
      "Epoch 118/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14407.9365\n",
      "Epoch 119/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13970.2422\n",
      "Epoch 120/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14323.5791\n",
      "Epoch 121/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13991.7930\n",
      "Epoch 122/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13692.3369\n",
      "Epoch 123/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14219.2061\n",
      "Epoch 124/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 13936.4092\n",
      "Epoch 125/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13838.8125\n",
      "Epoch 126/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13925.6006\n",
      "Epoch 127/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 14098.7061\n",
      "Epoch 128/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 14141.3545\n",
      "Epoch 129/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14289.6699\n",
      "Epoch 130/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13884.7607\n",
      "Epoch 131/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14162.3408\n",
      "Epoch 132/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14226.0049\n",
      "Epoch 133/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14022.6533\n",
      "Epoch 134/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13688.3574\n",
      "Epoch 135/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13640.7988\n",
      "Epoch 136/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 14035.3721\n",
      "Epoch 137/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13443.5381\n",
      "Epoch 138/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13643.1982\n",
      "Epoch 139/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 13656.8340\n",
      "Epoch 140/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13881.0332\n",
      "Epoch 141/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13668.4199\n",
      "Epoch 142/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13944.3643\n",
      "Epoch 143/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14025.4863\n",
      "Epoch 144/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 14119.4619\n",
      "Epoch 145/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13898.9365\n",
      "Epoch 146/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13810.8975\n",
      "Epoch 147/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13734.4229\n",
      "Epoch 148/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13325.7744\n",
      "Epoch 149/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13300.2061\n",
      "Epoch 150/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13509.0723\n",
      "Epoch 151/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13481.8242\n",
      "Epoch 152/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13470.2979\n",
      "Epoch 153/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 14010.2881\n",
      "Epoch 154/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13740.4082\n",
      "Epoch 155/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13328.4326\n",
      "Epoch 156/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13677.8945\n",
      "Epoch 157/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13271.5098\n",
      "Epoch 158/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13029.0518\n",
      "Epoch 159/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13244.6279\n",
      "Epoch 160/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 13358.4424\n",
      "Epoch 161/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 13301.2529\n",
      "Epoch 162/200\n",
      "356/356 [==============================] - 3s 8ms/step - loss: 13780.7139\n",
      "Epoch 163/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13355.7402\n",
      "Epoch 164/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12905.4326\n",
      "Epoch 165/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13337.6797\n",
      "Epoch 166/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13083.1377\n",
      "Epoch 167/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13182.7109\n",
      "Epoch 168/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12885.0947\n",
      "Epoch 169/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13262.9434\n",
      "Epoch 170/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 13230.3779\n",
      "Epoch 171/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13108.0059\n",
      "Epoch 172/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 13044.4600\n",
      "Epoch 173/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 13130.2168\n",
      "Epoch 174/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13004.1260\n",
      "Epoch 175/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13086.3203\n",
      "Epoch 176/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 13039.8691\n",
      "Epoch 177/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 13132.1094\n",
      "Epoch 178/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13096.7461\n",
      "Epoch 179/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12738.3916\n",
      "Epoch 180/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12966.6572\n",
      "Epoch 181/200\n",
      "356/356 [==============================] - 4s 10ms/step - loss: 13196.9648\n",
      "Epoch 182/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 12853.7441\n",
      "Epoch 183/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12836.0635\n",
      "Epoch 184/200\n",
      "356/356 [==============================] - 4s 11ms/step - loss: 13181.8730\n",
      "Epoch 185/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12683.5996\n",
      "Epoch 186/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12851.5029\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 3s 10ms/step - loss: 12982.1709\n",
      "Epoch 188/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 12991.6924\n",
      "Epoch 189/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 12996.5859\n",
      "Epoch 190/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13768.9785\n",
      "Epoch 191/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 13382.1680\n",
      "Epoch 192/200\n",
      "356/356 [==============================] - 3s 10ms/step - loss: 12436.0615\n",
      "Epoch 193/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13186.0928\n",
      "Epoch 194/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13524.5801\n",
      "Epoch 195/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13278.7295\n",
      "Epoch 196/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13126.8555\n",
      "Epoch 197/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 12798.7432\n",
      "Epoch 198/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13003.1221\n",
      "Epoch 199/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13372.5898\n",
      "Epoch 200/200\n",
      "356/356 [==============================] - 3s 9ms/step - loss: 13101.1943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08e08d7eb0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(dataset.iloc[17487:18718, 0:3])\n",
    "y_test = np.array(dataset.iloc[17487:18718, 3:4])\n",
    "\n",
    "x_test = x_test[0:n_steps_in].reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_test, verbose=0)\n",
    "\n",
    "y_test = y_test[n_steps_in:n_steps_in+n_steps_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f087f6a8a60>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU1fnA8e+bPSRASEggLCFAKIssUUIERAUURVTUuuG+gFgV+2u1tlVb19rWbraulargggvuiOCGKIgSCBI22cIOCSQkEAhL1vf3x73oiIRMIMlNMu/neeZh5s65Z947T7jv3HPOPUdUFWOMMYEnyOsAjDHGeMMSgDHGBChLAMYYE6AsARhjTICyBGCMMQEqxOsAaqJ169aanJzsdRjGGNOoLFq0aKeqxh++vVElgOTkZDIzM70OwxhjGhUR2XSk7dYEZIwxAcoSgDHGBChLAMYYE6CqTQAiEiEiC0RkiYisEJEH3e3Pu9uWishbIhLtbr9eRPJFJMt9jKui3v4iskxEskXkcRGR2j00Y4wxR+PPFUAJMFxV+wGpwEgRGQj8WlX7qWpfYDMwwWefN1Q11X08V0W9zwA3Ad3cx8hjPgpjjDE1Vm0CUEex+zLUfaiq7gFwf7lHAn7PKiciiUALVZ2vzmx0LwEX1jR4Y4wxx86vPgARCRaRLCAP+FRVM9ztk4DtQA/gCZ9dLvZpGup4hCrbA1t9Xm91tx3ps8eLSKaIZObn5/sTrjHGGD/4lQBUtUJVU4EOQLqI9Ha33wC0A1YCl7vFPwCS3aahT4EXjydAVZ2oqmmqmhYf/5P7GIwxpknLztvLQx98R3lFZa3XXaNRQKq6G5iNT3u9qlYArwMXu68LVLXEffs5oP8RqtqGk0wO6eBuM8YYA6zIKeLWKYsY8dgcXl+4mZW5e2v9M6q9E1hE4oEyVd0tIpHACOBvIpKiqtluH8BoYJVbPlFVc93dR+NcHfyIquaKyB63MzkDuJYfNyEZY0xAytqymyc/X8tnK/NoHh7CbUNTuHFIZ2Kjwmr9s/yZCiIReFFEgnGuGKYCHwJzRaQFIMAS4Ba3/C9FZDRQDhQC1x+qSESy3KYkgFuByTgdyDPdhzHGBKQFGwp54vO1zF27k5hmodwx4mdcNziZlpGhdfaZ0piWhExLS1ObC8gY01SoKl9l7+SJz7NZsKGQ1tFh3HRqF64a2Ino8Nqbqk1EFqlq2uHbG9VkcMYY0xSoKp+vyuOJz7PJ2rKbti0iuP/8XowZkERkWHC9xWEJwBhj6kllpfLRiu088Xk2K3P30KFVJH++qA8X929PeEj9nfgPsQRgjDH1YM/BMm6b8i1z1+6kS+so/nFpPy5IbUdosHdTslkCMMaYOpaz+wA3Tl5Idl4xD1/YmyvTkwgO8n76M0sAxhhTh5ZvK+LGyQs5UFrB5BvSGdKttdchfc8SgDHG1JHZq/K47dVviYkM5a1bBtO9bXOvQ/oRSwDGGFMHXpm/ifveX06vdi14/roBtGkR4XVIP2EJwBhjalFlpfLoR6t4ds56hvdI4IkrTiSqFsf016aGGZUxxjRCB8squHPqEj5clsvVA5N44PwTCPFwlE91LAEYY0wtKCgu4aaXMvl2827uHdWTcad2pqEvdGgJwBhjjtP6/GJumLyQ7UUHefqqkxjVJ9HrkPxiCcAYY47Dwo2F3PRSJkEivHrTQPp3auV1SH6zBGCMMcfogyU53Dl1Ce1bRTL5hgF0iovyOqQasQRgjDE1tL3oIJO+3sCzX65nQHIrJl6TRqs6mK+/rlkCMMYYP1RUKl+uyePVjC3MXp1HRaXy85Pa8+eL+hARWv8TudUGSwDGGHMUuUUHeGPhFqYu3EJO0cHv5+wfM6Ajya0bV5PP4fxZEjICmAOEu+XfUtX7ReR5IA1nRbA1wPWqWiwidwDjcFYEywduVNVNR6j3C5zVxg64m85S1bzjPyRjjDk+5RWVfLE6n9cWbGb26jwqFU7t1po/nNeLM3u2ISyk4Y7trwl/rgBKgOHuyT0U+EpEZgK/VtU9ACLyL2AC8FdgMZCmqvtF5Bbgb8DlVdR9laraEl/GmAZh2+4ffu1v33OQ+Obh3DK0K5enJZEU18zr8GpdtQlAnTUji92Xoe5DfU7+grOur7rlZ/vsPh+4ujYDNsaY2qSqzF6dx8vfbOKLNfkAnNYtngdGn8AZPRM8na+/rvnVB+AuCL8ISAGeUtUMd/skYBTwHXDnEXYdy9EXe58kIhXA28CftDEtUGyMafQKikv4w3vLmbl8OwnNw5kwLIXL0jrSMbbp/do/Er8SgKpWAKkiEgO8KyK9VXW5qt7gJocncJp5Jh3aR0SuxukjOL2Kaq9S1W0i0hwnAVwDvHR4IREZD4wHSEpK8v/IjDHmKD5ZsZ173l1G0YEyfjuyOzed2qVJ/9o/khodraruBmYDI322VQCvAxcf2iYiZwL3AqNVtaSKura5/+4FXgXSqyg3UVXTVDUtPj6+JuEaY8xPFB0o446pWYx/eREJzSP44PYh3Do0JeBO/uDfKKB4oExVd4tIJDAC+JuIpKhqttsHMBpY5ZY/EXgWGFnVqB4RCQFiVHWn27F8HvBZ7RySMcYc2Vdrd3LXW0vI21vC7cNTuH14tyYzoudY+NMElAi86Db1BAFTgQ+BuSLSAmcY6BLgFrf834Fo4E13JrzNqjoaQESyVDUVZ0jpx+7JPxjn5P+/WjsqY4zxsb+0nL/MWMXL8zfRNT6Kt28ZTGrHGK/D8pw/o4CWAice4a1Tqih/5lHqSnX/3Qf09zNGY4w5ZpkbC7nzzSVsLtzP2CGduevs7o32zt3aZncCG2OapINlFTz22RomzllP+5hIXrtpIAO7xHkdVoNiCcAY0+Qs31bEHVOzWLOjmCvSO3Lvub2IbqDLMnrJvhFjTJNRXlHJ01+s4/FZa4mNCmPSDQMY1j3B67AaLEsAxpgmobiknNtf/ZbZq/O5ILUdD44+gZhmjW+K5vpkCcAY0+jlFh3gxsmZrNmxlz9d2JurB3byOqRGwRKAMaZRW76tiLEvLmRfSQUvXD+A039mN4z6yxKAMabR+uy7Hfzy9cXERIby1i2D6NG2hdchNSqWAIwxjdKkeRt4ePp39G7fkueuTSOhRYTXITU6lgCMMY1KRaXy8PTvmPz1Rs7q1YZ/j0mlWZidyo6FfWvGmEZjX0k5v3xtMbNW5XHTqZ35/Tk9CQ4Sr8NqtCwBGGMahe1FB7lx8kJW79jLwxf25hob6XPcLAEYYxq8FTlFjJ2cSXFJOc9fl8ZQu7mrVlgCMMY0aLNW7uD21xbTMjKUN38xiJ6JNtKntlgCMMY0WJPnbeCh6d/Rq10Lnr9uAG1spE+tsgRgjGkQDpZVsDJ3D8u2FbFkSxFLt+5mbV4xI3q14T820qdO2DdqjKl3peWVrN6+l6XbdrNsaxFLtxaxZsdeyisVgLioMPp2aMmY9CSuH5xsI33qiCUAY0ydyy06wJw1+SzdWsSybUWsyt1LaUUlADHNQunTviU39+hCn/Yx9O3QksSWEbgrCpo65M+awBHAHJxlHEOAt1T1fhF5HkjDWRJyDXC9qhaLSDjwEs6KXwXA5aq68Qj1jgT+g7Mk5HOq+tfaOSRjTENxoLSCZ75cx7NfrqOkvJLm4SH06dCSG4Yk09c92XdoFWkne4/4cwVQAgx3T+6hwFciMhP4taruARCRfwETgL8CY4FdqpoiImOAR4HLfSt01xd+CmeB+a3AQhGZpqrf1daBGWO8o6rMXL6dRz5cybbdBxjdrx23D0+ha3w0Qdac02D4syawAsXuy1D3oT4nfwEiAXXLXAA84D5/C3hSRMSt55B0IFtV17t1vO7uZwnAmEZu9fa9PPjBCr5eV0DPxBY8dnkq6Z1jvQ7LHIFffQDuL/ZFQArwlKpmuNsnAaNwTtx3usXbA1sAVLVcRIqAOGCnT5Xfl3FtBU6u4rPHA+MBkpKS/Dqon/jir5CzuOb7RbWGIXdAXNdj+1xjAkjR/jIe+2wNL8/fRPOIEB6+sDdXpidZB24D5lcCUNUKIFVEYoB3RaS3qi5X1Rvc5PAETjPPpNoOUFUnAhMB0tLStJriR3ZgF+zNrfl+G+bCktchfTycdhc0s18xxhyuolJ5M3MLf/t4Nbv3l3LlyUncOaI7raJsNa6GrkajgFR1t4jMBkYCy91tFW4Tzm9xEsA2oCOwVURCgJY4ncG+DpU5pIO7rW6c8+ix7bd3B8x+BDL+C1mvwtDfQ9pYCLE/bGMAFm3axQPTVrBsWxHpybHcP7oXJ7Rr6XVYxk9B1RUQkXj3lz8iEonTcbtaRFLcbQKMBla5u0wDrnOfXwJ8flj7P8BCoJuIdBaRMGCMu1/D0rwNjH4cbp4L7VLho9/D0wNh1Yfwk0MyJnDk7TnIHVOzuPiZr8nfW8J/xqTyxs0D7eTfyPhzBZAIvOg29QQBU4EPgbki0gJnGOgS4Ba3/PPAyyKSDRTinNwRkXY4wz1HuX0DE4CPcYaBvqCqK2rxuGpX295wzXuw9lP45F54/UpIPhXOfgQS+3kdnTH1Zs/BMqbM38xTs7MpLa/k1qFduW1YClHhdktRYyQ//XHecKWlpWlmZqa3QVSUwaLJMPvPTt9C6lUw/A/QItHbuIypQ5sK9jFp3kbezNzCvtIKzuiRwB/P60Vy6yivQzN+EJFFqpp2+HZL2zUVHArpN0GfS2HuP53+gRXvwCm/gsETIMz+Q5imQVWZv76QF+Zt4LOVOwgJEs7v244bTulMnw7W1NMU2BXA8SpcD589AN+9D83bwZn3Q9/Lwe5sNI3UwbIKPliSwwvzNrIydw+xUWFcfXISVw/sZOvuNlJ2BVBXYrvAZS/Bpm/g43vg3ZuhshxOvNrryIypkfy9JbwyfxNTMjaxs7iU7m2a8+jFfbggtT0RocFeh2fqgCWA2tJpEIybBS+c7VwR9DwfIuwy2TR8K3KKmDRvI9OyciitqOSMHgncOKQzg7vG2Rw9TZwlgNoUFASj/g4Thzp3H4/8i9cRGVOl+esL+M9na/lmfQGRocGMSe/I9YOT6RIf7XVopp5YAqht7VKh/3WQ8SycdC0k9PQ6ImN+ZNnWIv728Srmrt1Jmxbh3H1OD8YMSKJls1CvQzP1zBJAXRh+H6x4D2b+Fq6dZh3CpkHIztvLPz9Zw8zl22nVLJR7R/XkmkGdrH0/gFkCqAtRcc69ATN+AyunQa8LvI7IBLAthfv592dreXfxVpqFhfCrM7sxdkhnmkfYL/5AZwmgrvS/wblh7ON7IWUEhDXzOiITYPL2HuSpz7N5dcFmRISxQzpzy9AUYm2SNuOyBFBXgkPgnL/B5FEw798w7B6vIzIBomh/Gc/OWcekeRsprajk8gEduX14CoktI70OzTQwlgDqUvIp0Pti+OrfkHoltEr2OiLThO0rKWfy1xv575frKC4p54J+7fjVmT+z6RpMlSwB1LURD8PqmU5T0JgpXkdjmpidxSVkrC8kY0MBM5blsrO4lDN7tuHOs35Gz8QWXodnGjhLAHWtZXs47Tcw6yHIngUpZ3gdkWnE8vYcZP6GQjLWF5CxoZDsPGe11mZhwQzuGsetw1I4KamVx1GaxsISQH0YNAEWvwIzfwe3fG0Lyhi/5RYd+P4Xfsb6Qtbv3AdAdHgIacmtuPikDgzsEkvv9i0JDa52eQ9jfsQSQH0ICYeRf4VXL4MFz8Lg272OyDRQW3ft/+GEv6GQTQX7AWgeEUJ6cixj0jtycuc4TmjXghA74ZvjZAmgvvzsbOh2NnzxqDOVdPO2XkdkPKaqbN11gPnrC5jvnvS37joAQMvIUNI7x3LNwE4M7BJHz8QWtri6qXWWAOrTyL84S0p+9gBc9F+vozH1TFXZXLif+esL3F/5hWzb7ZzwWzUL5eTOcYwd0pmBXeLo3qY5QXbCN3Ws2gQgIhHAHCDcLf+Wqt4vIlOANKAMWADcrKplInIXcJVP/T2BeFUtPKzeycDpQJG76XpVzTr+Q2rA4ro6/QFf/cu5USzpZK8jMnVIVdmwcx8Zbqft/PWFbN9zEIC4qDBO7hLL+NO6MLBLHN0Sou2Eb+pdtQvCuIu+R6lqsYiEAl8B/wfEAjPdYq8Cc1T1mcP2PR/4taoOP0K9k4HpqvqWv8E2yAVhaqqkGJ4cANHxcNNsCLJ5WJqKikpl9fa9LNhQwIKNhSzYsIudxSUAtI4OZ2CXWE7uEsfAzrGkJETbVMum3hzzgjDqZIhi92Wo+1BVneFT+QKgwxF2vwJ47ZgibqrCo+Gsh+HtsfDtS5B2g9cRmWNUWl7Jsm1FLNhQyMKNzmPvwXIA2sdEcmq31gxIjiW9cyxd46PshG8aHL+WhBSRYGARkAI8paq/83kvFMgA/k9V5/psbwZsBVIOb/5x358MDAJKgFnA71W15AjlxgPjAZKSkvpv2rSpJsfXMKnC5HMhbyXcvgiaxXodkfHDgdIKFm/eRcaGQhZsKGTxll0cLKsEoGt8FOmd40jv3IoBybF0aGVzP5mGo6orgBqtCSwiMcC7wO2qutzd9j9gn6r+6rCylwNXq+r5VdSVCGwHwoCJwDpVfehon98kmoAO2b4Mnj0N0sbCuf/wOhpThcpK5et1BbyRuYWPV2yntLySIIFe7VowIDmWkzvHkpYcS+vocK9DNaZKtbImsKruFpHZwEhguYjcD8QDNx+h+BiO0vyjqrnu0xIRmQT8piaxNHpt+zgn/8znof/10La31xEZH7lFB3gzcytTM7ewddcBWkSEMGZAR4b3SKB/p1Y2lbJpEvwZBRQPlLkn/0hgBPCoiIwDzgbOUNXKw/ZpiTPCp8qV0UUkUVVz3U7mC4Hlx3EcjdOwe2D5287CMdd/aAvHeKy0vJJZK3fwRuYW5qzJp1JhcNc47jq7O2ef0NYWTjFNjj9XAInAi24/QBAwVVWni0g5sAn4xu3cesenCeci4BNV3edbkYjMAMapag4wxU0uAmQBv6iVI2pMmsXCGffB9F/Bf4dAcAP9VRkRA+c9BrGdvY6kTmTn7eWNhVt459ttFOwrpW2LCG4blsKl/TuSFGdt+abpqlEfgNeaVB/AIZUV8Ol9sHON15FUbUsGNIuDsZ9CVGuvo6kV+0rK+XBpLm9kbmHRpl2EBAln9mzD5QM6ctrP4u2uW9Ok1EofgKkDQcFw9iNeR3F0mzPgpdEw5VK4fjqENc755SsqlW/WFfDu4m18tDyXfaUVdImP4p5RPbjoxA7EN7eOXBNYLAGY6iWdDJdMgjeugjevhzGvNtzmqsOoKity9vB+1jbez8ohb28JzcNDOLdvIpeldaR/p1Y2Pt8ELEsAxj89RsG5/3L6K6b/CkY/2aA7rbfu2s/7WTm8t3gba/OKCQ0WhnZP4MLU9pzRM8E6dI3BEoCpibQbYG8ufPkoNE+E4X/wOqIfKdpfxofLcnlv8TYWbHTuPRyQ3Io/Xdibc/sk0soWQzfmRywBmJoZereTBOb83UkCA8Z6Gk5JeQWfr8zjvaxtzF6VT2lFJV3jo7jr7O6M7teOjrE2iseYqlgCMDUjAuc+BsV5MOM3EN0Gep5X72Hk7TnIK/M38eqCzewsLiW+eTjXDurEhSe254R2Laxd3xg/WAIwNRccApe8AC+Odia1u/Z9SBpYLx+dtWU3k+Zt4MOluVSockaPBK4ZlMyQlNY2dNOYGrIEYI5NWBRcORVeOAtevRxu/BgSetTJR5VVVDJjWS6Tv97I4s27iQ4P4dpByVw7qBPJrRvnkFRjGgJLAObYRcXB1W/D82fBKxfDuE+hRbtaq76guIRXMzbzSsYmduwpoXPrKB44vxeXpHUkOtz+dI05Xva/yByfVslw1Zsw6VznRrEbZkBEy+OqckVOEZPnbeT9JTmUlldyarfW/PXnfTn9Z/G2apYxtcgSgDl+if3g8pedBPD6Vc5VQUjN7qrdV1LOrFV5vDJ/Ews2FBIZGsxlaR24fnAyKQnN6yhwYwKbJQBTO7oOgwufgXfGwbs3w8UvQFDQUXcpLiln1sodzFy2nS/W5HGwrJIOrSK5d1RPLkvrSMtmjeNuY2MaK0sApvb0vdS5R+DTPzr3CJz955/cLbznYBmzVu7gw6XbmbM2n9LyShKah3N5WkfO6ZPIgORYG81jTD2xBGBq1+DbnSQw/2knCZzyS4r2l/HJd9uZuXw7c9fmU1ahJLaM4OqTOzGqT1tOSmplbfvGeMASgKldInDWI5TuziHs0z/yzLf7+WduX8orlfYxkVw/OJlz+iSS2iHGTvrGeMwSgKlVew+W8cwX63hx+cU8H7SacQV/J6bvfzhhyHn0ad/S7tA1pgGxBGBqRUWlMjVzC//8ZDU7i0u56MQkWgyYSsjMy7hiw90wNBUkxuswjTE+jj5MAxCRCBFZICJLRGSFiDzobp8iIqtFZLmIvCAioe72oSJSJCJZ7uO+KurtLCIZIpItIm+IiE3V2EjNy97JuY/P5e53lpEcF8V7t53CY5en0qtLEnL1WxAWDVMugd1bvA7VGOOj2gQAlADDVbUfkAqMFJGBwBSgB9AHiATG+ewzV1VT3cdDP6nR8SjwmKqmALsAb6eVNDW2Pr+YcS8u5KrnMiguKefJK0/kzV8MIrWjzy/9lh3g6regdJ+TBA7s8i5gY8yPVJsA1FHsvgx1H6qqM9z3FFgAdPD3Q8VpCB4OvOVuehG4sEaRG8/s3l/Kgx+s4KzH5jB/fSG/Hdmdz+44nfP6tjtyG3+bE2DMFChc79woVnaw/oM2xvyEP1cAiEiwiGQBecCnqprh814ocA3wkc8ug9wmo5kicsIRqowDdqtquft6K9C+is8eLyKZIpKZn5/vT7imjpRVVDJp3gaG/uMLXvx6I5emdWD2b4Zy69CU6lfY6nyac6PYpnnOjWKVlfUTtDGmSn51AqtqBZAqIjHAuyLSW1WXu28/DcxR1bnu62+BTqpaLCKjgPeAbscaoKpOBCYCpKWl6bHWY46dqvL5qjwembGS9fn7OCUljj+c24ueiS1qVlGfS5x7BD75A3zSDkb+pW4CNsb4pUajgFR1t4jMBkYCy0XkfiAeuNmnzB6f5zNE5GkRaa2qO32qKgBiRCTEvQroAGw7ngMxta+0vJI5a/KZ/PVGvsreSZfWUTx3bRpn9Ew49uGcgyZA0TbnRrEW7WHwhNoN2hjjt2oTgIjEA2XuyT8SGAE8KiLjgLOBM1S10qd8W2CHqqqIpOM0MxX41um+Nxu4BHgduA54v7YOyhy7ikolY0MB07JymLl8O0UHyoiNCuO+83px9cBOhIX41WpYNRFnioi9OfDJvdC8rXNlYIypd/5cASQCL4pIMM7JfKqqTheRcmAT8I37a/Add8TPJcAt7vsHgDFuRzEiMgMYp6o5wO+A10XkT8Bi4PlaPjbjJ1VlydYipmXlMH1pDnl7S2gWFsxZvdowOrUdQ1Lij//E7ysoCC6aCMX58N4tEJ3g9BEYY+qVuOfmRiEtLU0zMzO9DqPJWLtjL+9n5fDB0hw2FewnLDiIod3jGZ3ajjN6tCEyrJqO3eN1YBe8MBL25MCNHzmjhYwxtU5EFqlq2uHb7U7gALOlcD8fLM1hWlYOq7bvJUhgcNfW3DY0hbN7t6VlZD1OwRzZCq56C54fAa9c4qwo1tLv0cTGmONkCaCRK6uoZNe+Ugr2lVJ46N/ikh+e+/x76AFwUlIMD5zfi1F9E0loHuHdAcR0dJLApHOcJHDFaxAa6V08RxMU6iyDaUwTYQmgkdmx5yAzluUyY1kua3YUU3Sg7IjlRKBVszBio5xHt4RoYqPCSIptxqg+iXSMbVbPkR9F295w+SvOusKPp3odzdGljIARD0GbXl5HYsxxswTQCOTvLWHm8lymL81l4cZCVKFH2+aM7teOuOgw4qLCiI0KJzYqjLho54TfqllY41pYpcvpMPYTyM3yOpKq7d0BGc/Af0+BE6+BYfc4o5iMaaSsE7iBKigu4aMV25m+JJeMDQVUKqQkRHNe30TO65to6+R6ZX8hzPk7LPgfBIfBKf/n3MsQFuV1ZMZUqapOYEsADciufaV8vGI7Hy7L5et1BVRUKl1aR3Fe30TO7duO7m3tpN9gFKyDzx6AldMgui0M/wOkXglBdTxyyphjENAJYPrSHMorlBG92hAV3rBavfL3ljB7VR4fLstlXvZOyiuVTnHNnJN+n3b0TGxui6g0ZJvnw8f3wrZMaNMbznoYug73OipjfiSgh4G+sXALc9fuJCI0iDN7tuGC1Pac/rNavrnJT5WVyoqcPcxatYPZq/JYsrUIgA6tIhl3ahfO65vICe1a2Em/sUgaCOM+gxXvOlcEL18EKWfCiIeto9g0eAFxBVBZqSzavIv3s7YxY9l2CveV0jIylFF92jK6X3vSO8fWaYdpcUk5X63dyexVeXy+Oo/8vSWIQGrHGIZ3T2BYjwQ76TcF5SWwYKLTR1CyF068Gobdax3FxnMB3QTkq6yikq+ydzItK4ePV2xnf2kFbVqEc37fdlyQ2p7e7WvnRLxx5z4+X5XH7NV5zF9fQFmF0jw8hNO6xzO8ewJDu8cTFx1+3J9jGqDDO4oveBJ6/9zrqEwAswRwBAdKK/hs5Q6mLcnhi9V5lFUonVtHMbpfO0antqNrfPT3ZSsrlX2l5ewrqaC4pJziknL2HfZvcUk5eXtKmLM2n/X5+wDoGh/FGT3bMKx7AmnJrQgNrv9mJ+ORgnXwzk1QkA23fwtRrb2OyAQoSwDVKNpfxszlubyflcP8DQWoQvuYSMoqKtlXUs6+0gq/6gkLCeLkzrEM75HA8B4JdIqz4YEBLW+Vc99A6lUw+nGvozEBKqA7gf3RslkoY9KTGJOexPaig0xfmsPSrUU0CwsmKjyEqPAQosODiQ4PJSo8mOjvt4X86HlEaJC15ZsfJPSAk38B3zwF/a+D9v29jsiY79kVgDF17eAeeDLNWQBn3CxnOmxj6lFVVwD2l2hMXYtoAWf9CXK+haxXvI7GmO9ZAjCmPvS5FJIGOfcK7C/0OhpjAEsAxtQPERj1d2cRnNl/9joaYwA/EoCIRIjIAhFZIiIrRORBd/sUEQJiBY0AAA7gSURBVFktIstF5AURCXW3XyUiS0VkmYh8LSL9qqh3sohsEJEs99HA5wE25ji17QMDxkHm85C71OtojPHrCqAEGK6q/YBUYKSIDASmAD2APkAkMM4tvwE4XVX7AA8DE49S912qmuo+GvA8wMbUkmH3QmQszLgLGtEADNM0VZsA1FHsvgx1H6qqM9z3FFgAdHDLf62qu9zy8w9tN8YAkTFw5gOwZT4sfcPraEyA86sPQESCRSQLyAM+VdUMn/dCgWuAj46w61hg5lGqfsRtLnpMRI44L4KIjBeRTBHJzM/P9ydcYxq21KugfRp88kdniKgxHvErAahqhaqm4vyaTxeR3j5vPw3MUdW5vvuIyDCcBPC7Kqq9G6cJaQAQW1U5VZ2oqmmqmhYfH+9PuMY0bEFBTofwvnz48lGvozEBrEajgFR1NzAbGAkgIvcD8cAdvuVEpC/wHHCBqhZUUVeu24JUAkwC0msevjGNVPuTnDuD5z8DeSu9jsYEKH9GAcWLSIz7PBIYAawSkXHA2cAVqlrpUz4JeAe4RlXXHKXeRPdfAS4Elh/PgRjT6Ay/D8KbW4ew8Yw/VwCJwGwRWQosxOkDmA78F2gDfOMO47zPLX8fEAc87W7/fu4GEZkhIu3cl1NEZBmwDGgN/Kl2DsmYRiIqDs74I2yc6ywoY0w9s7mAjPFSZQVMHAr7C+C2BRAeXe0uxtSUzQVkTEMUFAyj/gF7tsHcf3gdjQkwlgCM8VrSydDvSvj6SdiZ7XU0JoBYAjCmIRjxIIRGwszfWoewqTeWAIxpCKITYNg9sG4WrPrQ62hMgLAEYExDMeAmSOgFH90NZQe8jsYEAFsS0piGIjjEuUN48rnw9jhoc0Ldf2ZIOKTfbKOPApQlAGMakuQhzgl5wbOwanr9fKZWwml31c9nmQbF7gMwJpC9fBHsWAG/WuZcDZgmye4DMMb81ODboXgHLHvT60iMBywBGBPIugyDNr2dexAaUWuAqR2WAIwJZCIw6DbIXwnZs7yOxtQzSwDGBLrel0B0W/jmCa8jMfXMEoAxgS4kDE6+GdZ/AduXeR2NqUeWAIwxkHYDhEbBN095HYmpR5YAjDEQ2QpOvNoZDbQnx+toTD2xBGCMcQy8xbkpLONZryMx9cQSgDHGEdsZep4PiyZBSbHX0Zh64M+awBEiskBElojIChF50N0+RURWi8hyEXlBRELd7SIij4tItogsFZGTqqi3v4gsc8s97q4NbIzx0qDb4WARLH7F60hMPfDnCqAEGK6q/YBUYKSIDASmAD2APkAkMM4tfw7QzX2MB56pot5ngJt8yo48xmMwxtSWjgOg48kw/ymoKPc6GlPHqk0A6jh0PRjqPlRVZ7jvKbAA6OCWuQB4yX1rPhAjIom+dbqvW6jqfHf/l4ALa+mYjDHHY/DtsHszrPrA60hMHfOrD0BEgkUkC8gDPlXVDJ/3QoFrgI/cTe2BLT67b3W3+Wrvbj9amUP1jxeRTBHJzM/P9ydcY8zx6D4KWnW26SECgF8JQFUrVDUV51d+uoj09nn7aWCOqs6tiwBVdaKqpqlqWnx8fF18hDHGV1CwMz3EtkzYklF9edNo1WgUkKruBmbjtteLyP1APHCHT7FtQEef1x3cbRxWpkM1ZYwxXkm90rk34GubHqIp82cUULyIxLjPI4ERwCoRGQecDVyhqpU+u0wDrnVHAw0EilQ117dO9/UeERnojv65Fni/dg7JGHPcwqIgbayzPnHBOq+jMXXEnyuARGC2iCwFFuL0AUwH/gu0Ab4RkSwRuc8tPwNYD2QD/wNuPVSR249wyK3Ac265dcDM4zwWY0xtSh8PwaEw/2mvIzF1pNolIVV1KXDiEbYfcV93VM9tVbyX6vM8E+h9pHLGmAageRvocxksngLD7oVmsV5HZGqZ3QlsjKna4AlQfgAWPu91JKYOWAIwxlQtoSeknAkLJkLZQa+jMbXMEoAx5ugGTYB9ebZucBNkCcAYc3RdhkKbPvCN3RjW1FgCMMYcnYjTF5C/CrI/8zoaU4ssARhjqnfCz6F5ot0Y1sRYAjDGVO/QusEbvoTcpV5HY2qJJQBjjH/63wBh0U5fgGkSqr0RzBhjAIiMgROvgYX/cyaLi6yHG8MiWkJEi7r/nABlCcAY47+Bt8CCZ+HZ0+rn84LDYdCtMOTXTjIwtcoSgDHGf606wbXTYNfG+vm8jXPhq8fg25dg6N3Q/3pnfiJTK0Qb0bjetLQ0zczM9DoMY0x9ylkMn/zRSQZxKTDiIWfRGltG3G8iskhV0w7fbp3AxpiGrd2JcN0HcMXrgMDrV8Lkc2Hbt15H1uhZAjDGNHwi0P0cuPUbOPefkL8a/jcM3r7JWb/YHBNLAMaYxiM4FAaMg18uhlPvhJXT4Ik0+PR+OFjkdXSNjiUAY0zjE9ECzrgPJmTCCRfBvH/D4ydCxkSoKPM6ukbDEoAxpvGK6Qg/fxbGfwkJvWDmXfD0INiT43VkjYI/awJHiMgCEVkiIitE5EF3+wQRyRYRFZHWPuXvcpeIzBKR5SJSISI/uWNERCaLyAafsqmHlzHGGL+0S/2ho7hoC3x0t9cRNQr+XAGUAMNVtR+QCox0F3ufB5wJbPItrKp/V9VUd/nHu4EvVbWwirrvOlRWVbOqKGOMMdU71FF86p3w3Xuw7nOvI2rwqk0A6ih2X4a6D1XVxaq6sZrdrwBeO74QjTGmBgb/Elp1hhl3QXmJ19E0aH71AYhIsIhkAXnAp6qa4cc+zYCRwNtHKfaIiCwVkcdEJLyKesaLSKaIZObn5/sTrjEmkIVGwKh/QEG2TVxXDb8SgKpWuE06HYB0Eentx27nA/OO0vxzN9ADGADEAr+r4rMnqmqaqqbFx8f7E64xJtB1OxN6nAdf/h12b/E6mgarRqOAVHU3MBvnl311xnCU5h9VzXWbl0qASUB6TWIxxpijGvlX59+Pfu9tHA2YP6OA4kUkxn0eCYwAVlWzT0vgdOD9o5RJdP8V4EJguf9hG2NMNWI6wul3warpsPZTr6NpkPy5AkgEZovIUmAhTh/AdBH5pYhsxWkWWioiz/nscxHwiaru861IRGaISDv35RQRWQYsA1oDfzregzHGmB8ZNMGZQG7GXVB20OtoGhybDdQY07St+xxevgiG3Qun/9braDxhs4EaYwJT1+HQ60KY+8/6W8egkbAEYIxp+s7+M0gwzLQOYV+WAIwxTV/L9jD0d7BmJqye6XU0DYYlAGNMYBh4K8T3gJm/g7IDXkfTIFgCMMYEhuBQ5w7h3ZucdYaNJQBjTADpfCr0uRS++jcUrPM6Gs9ZAjDGBJaz/gTBYU5TUCMaBl8XLAEYYwJL87Yw7B7I/hRWfeh1NJ6yBGCMCTzp4yHhBGeeoNL9XkfjGUsAxpjAExwC5/7DWT1s7j+8jsYzlgCMMYGp02DodwXMexx2ZnsdjScsARhjAteIhyC0Gcz4TUB2CId4HYAxxngmOgGG/wFm3gVPpkFQAz4lXvE6xHau1Sob8NEaY0w9SLsR9uZA4XqvIzm6kCOumnt8VdZ6jcYY05gEh8CZD3gdhSesD8AYYwKUP0tCRojIAhFZIiIrRORBd/sEEckWERWR1j7lh4pIkYhkuY/7qqi3s4hkuHW8ISJhtXdYxhhjquPPFUAJMFxV+wGpwEgRGQjMA84ENh1hn7mqmuo+Hqqi3keBx1Q1BdgFjK15+MYYY45VtQlAHcXuy1D3oaq6WFU3HsuHugvBDwfecje9iLMwvDHGmHriVx+AiASLSBaQh7MofEY1uwxym4xmisgJR3g/DtitquXu661Ae7+jNsYYc9z8SgCqWqGqqUAHIF1Eeh+l+LdAJ7fJ6AngveMJUETGi0imiGTm5+cfT1XGGGN81GgUkKruBmYDI49SZs+hJiNVnQGE+nYSuwqAGBE5NAy1A7CtivomqmqaqqbFx8fXJFxjjDFH4c8ooHgRiXGfRwIjgFVHKd/WbeNHRNLdzyjwLaOqipNILnE3XQe8fywHYIwx5tiIVjP/hYj0xemkDcY5mU9V1YdE5JfAb4G2OH0DM1R1nIhMAG4ByoEDwB2q+rVb1wxgnKrmiEgX4HUgFlgMXK2qJdXEks+RRx35ozWw8xj3bUrse3DY9/AD+y4cTfl76KSqP2lCqTYBNBUikqmqaV7H4TX7Hhz2PfzAvgtHIH4PdiewMcYEKEsAxhgToAIpAUz0OoAGwr4Hh30PP7DvwhFw30PA9AEYY4z5sUC6AjDGGOPDEoAxxgSogEgAIjJSRFa7U0//3ut4vCIiG0VkmTtNd6bX8dQXEXlBRPJEZLnPtlgR+VRE1rr/tvIyxvpQxffwgIhs85m+fZSXMdYHEekoIrNF5Dt3ivv/c7cH3N9Ek08AIhIMPAWcA/QCrhCRXt5G5alh7jTdgTTeeTI/nb7k98AsVe0GzHJfN3WTOfI0Lo/5TN8+o55j8kI5cKeq9gIGAre554SA+5to8gkASAeyVXW9qpbi3H18gccxmXqkqnOAwsM2X4BzhzsEyHTkVXwPAUdVc1X1W/f5XmAlzmzEAfc3EQgJoD2wxed1IE89rcAnIrJIRMZ7HYzH2qhqrvt8O9DGy2A8NkFElrpNRE2+2cOXiCQDJwIZBODfRCAkAPODIap6Ek5z2G0icprXATUE7uSEgToe+hmgK85qf7nAP70Np/6ISDTwNvArVd3j+16g/E0EQgLYBnT0eV3l1NNNnapuc//NA97FaR4LVDtEJBHA/TfP43g8oao73PU+KoH/ESB/EyISinPyn6Kq77ibA+5vIhASwEKgm7sIfRgwBpjmcUz1TkSiRKT5oefAWcDyo+/VpE3DmYYcAng68kMnPNdFBMDfhDtd/fPASlX9l89bAfc3ERB3ArtD2/6NM6X1C6r6iMch1Tt3+u133ZchwKuB8j2IyGvAUJzpfncA9+OsVDcVSMKZYvwyVW3SHaRVfA9DcZp/FNgI3OzTDt4kicgQYC6wDKh0N9+D0w8QWH8TgZAAjDHG/FQgNAEZY4w5AksAxhgToCwBGGNMgLIEYIwxAcoSgDHGBChLAMYYE6AsARhjTID6fw/uVQWScD14AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(yhat[0])\n",
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeled = yhat.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nash(observed, modeled):\n",
    "    \n",
    "    mean_obs = np.mean(observed)\n",
    "    \n",
    "    variance = 0 \n",
    "    squared_err = 0\n",
    "    for t, obs_flow in enumerate(observed):\n",
    "        squared_err += (modeled[t] - obs_flow) ** 2\n",
    "        variance += (obs_flow - mean_obs) ** 2\n",
    "        \n",
    "        \n",
    "    nash = 1 - (squared_err  / variance)\n",
    "    return nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.2766338066871663"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nash(observed, modeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
