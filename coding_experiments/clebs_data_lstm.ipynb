{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_time_series_for_window(start_date, end_date, station, dataframe):\n",
    "    return dataframe.loc[start_date:end_date, [station]]\n",
    "\n",
    "\n",
    "def check_nan_values(dataframe):\n",
    "    return dataframe.isnull().values.any()\n",
    "\n",
    "\n",
    "def get_valid_sequences(df):\n",
    "    valid_sequences = []\n",
    "    starting_idx = 0\n",
    "\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        flow = row[0]\n",
    "\n",
    "        if np.isnan(flow):\n",
    "\n",
    "            if starting_idx < i-1:\n",
    "                valid_sequences.append((starting_idx, i))\n",
    "                starting_idx = i+1\n",
    "            else:\n",
    "                starting_idx = i+1\n",
    "                continue\n",
    "    \n",
    "    if not check_nan_values(df.iloc[starting_idx:, :]):\n",
    "        valid_sequences.append((starting_idx, len(df)))\n",
    "    return valid_sequences\n",
    "\n",
    "\n",
    "def valid_seqs_minimum_len(valid_seqs, seq_len):\n",
    "    \n",
    "    valid_seqs_min_len = []\n",
    "    pops = []\n",
    "    for i, (start, end) in enumerate(valid_seqs):\n",
    "        if end - start >= seq_len:\n",
    "            valid_seqs_min_len.append((start, end))\n",
    "\n",
    "    return valid_seqs_min_len\n",
    "\n",
    "\n",
    "\n",
    "def split_sequences(possible_seqs, split_len):\n",
    "    \n",
    "    usable_seqs = []\n",
    "    for seq in possible_seqs:\n",
    "        usable_seqs += get_seq_splits(seq, split_len)\n",
    "        \n",
    "    return usable_seqs\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_seq_splits(seq, split_len):\n",
    "    \n",
    "    start = seq[0]\n",
    "    end = seq[1]\n",
    "    \n",
    "    chunks = (end - start) // (split_len+1)     # +1 because there must be an unobserved item after each chunk\n",
    "                                                # which will be the y (after window value)\n",
    "\n",
    "    splits = []\n",
    "    prev_end_chunk = start\n",
    "    for i in range(chunks):\n",
    "\n",
    "        start_chunk = prev_end_chunk\n",
    "        end_chunk = start_chunk + split_len\n",
    "        splits.append((start_chunk, end_chunk))\n",
    "        prev_end_chunk = end_chunk+1\n",
    "        \n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_seq_obs_values(seq, df):\n",
    "    return np.array(df.iloc[seq[0]:seq[1], :]), np.array(df.iloc[seq[1], :])\n",
    "\n",
    "\n",
    "def split_seqs_train_test(train_frac, usable_seqs):\n",
    "    \n",
    "    total_seqs = len(usable_seqs)\n",
    "    train_amount = round(total_seqs * train_frac)\n",
    "    \n",
    "    random.shuffle(usable_seqs)\n",
    "    train_seqs = usable_seqs[0:train_amount]\n",
    "    test_seqs = usable_seqs[train_amount:]\n",
    "    \n",
    "    return train_seqs, test_seqs\n",
    "\n",
    "\n",
    "def mount_trainable_testable_arrays(seqs, df):\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for seq in seqs:\n",
    "        x, y = get_seq_obs_values(seq, df)\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    \n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "\n",
    "\n",
    "def transform_cleb_df_into_wal_df(cleb_df):\n",
    "    \n",
    "    index_names = {}\n",
    "    for i, (_, row) in enumerate(cleb_df.iterrows()):\n",
    "        \n",
    "        year = str(int(row[2]))\n",
    "        month = str(int(row[1]))\n",
    "        day = str(int(row[0]))\n",
    "        hour = str(int(row[3]))\n",
    "        index_name = year+'-'+month+'-'+day+'-'+hour\n",
    "        \n",
    "        index_names[i] = index_name\n",
    "        \n",
    "    \n",
    "    cleb_df.rename(index=index_names)\n",
    "    cleb_df = cleb_df.drop('day', 1)\n",
    "    cleb_df = cleb_df.drop('month', 1)\n",
    "    cleb_df = cleb_df.drop('year', 1)\n",
    "    cleb_df = cleb_df.drop('hour', 1)\n",
    "    return cleb_df.replace(-1, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow_path = \"/home/colombelli/Documents/hydro-ml/data/Vazao.txt\"\n",
    "rain_path = \"/home/colombelli/Documents/hydro-ml/data/Chuva.txt\"\n",
    "et_path = \"/home/colombelli/Documents/hydro-ml/data/ET.txt\"\n",
    "\n",
    "flow_df = pd.read_csv(flow_path, sep=\"\\t\", header=None)\n",
    "flow_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"flow\"]\n",
    "\n",
    "rain_df = pd.read_csv(rain_path, sep=\"\\t\", header=None)\n",
    "rain_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"rain\"]\n",
    "\n",
    "et_df = pd.read_csv(et_path, sep=\"\\t\", header=None)\n",
    "et_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"et\"]\n",
    "\n",
    "\n",
    "flow_df = transform_cleb_df_into_wal_df(flow_df)\n",
    "rain_df = transform_cleb_df_into_wal_df(rain_df)\n",
    "et_df = transform_cleb_df_into_wal_df(et_df)\n",
    "\n",
    "\n",
    "# this fixed val_seq was extracted from the other notebook (no complete automation yet - just a poc)\n",
    "val_seq = [(5962, 6051), (6078, 17486), (17487, 18718), (18741, 23437)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "import os\n",
    "import time\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(rnn_units): \n",
    "      return tf.keras.layers.LSTM(\n",
    "        rnn_units, \n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        recurrent_activation='sigmoid',\n",
    "        stateful=True,\n",
    "        dropout=0.3, \n",
    "        recurrent_dropout=0.3\n",
    "      )\n",
    "\n",
    "\n",
    "### Defining the RNN Model ###\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        # Layer 1: Embedding layer to transform indices into dense vectors \n",
    "        #   of a fixed embedding size\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "\n",
    "        # Layer 2: LSTM with `rnn_units` number of units. \n",
    "        LSTM(rnn_units),\n",
    "\n",
    "        # Layer 3: Dense (fully-connected) layer that transforms the LSTM output\n",
    "        #   into the vocabulary size.\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "      ])\n",
    "    return model\n",
    "\n",
    "\n",
    "### Defining the loss function ###\n",
    "def compute_loss(labels, logits):\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = model(x)\n",
    "        loss = compute_loss(y, y_hat)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105.84],\n",
       "       [107.3 ],\n",
       "       [108.76],\n",
       "       [109.86],\n",
       "       [110.6 ],\n",
       "       [111.34],\n",
       "       [111.34],\n",
       "       [111.34],\n",
       "       [112.84],\n",
       "       [113.97],\n",
       "       [115.48],\n",
       "       [117.4 ],\n",
       "       [120.11],\n",
       "       [122.86],\n",
       "       [126.05],\n",
       "       [129.7 ],\n",
       "       [134.24],\n",
       "       [138.45],\n",
       "       [142.31],\n",
       "       [145.79],\n",
       "       [150.68],\n",
       "       [155.66],\n",
       "       [159.8 ],\n",
       "       [164.01],\n",
       "       [169.25],\n",
       "       [175.09],\n",
       "       [180.54],\n",
       "       [186.61],\n",
       "       [192.8 ],\n",
       "       [199.12],\n",
       "       [205.02],\n",
       "       [211.02],\n",
       "       [216.57],\n",
       "       [222.22],\n",
       "       [228.52],\n",
       "       [237.34],\n",
       "       [309.1 ],\n",
       "       [480.25],\n",
       "       [603.53],\n",
       "       [619.39],\n",
       "       [632.24],\n",
       "       [646.36],\n",
       "       [659.56],\n",
       "       [675.17],\n",
       "       [687.59],\n",
       "       [702.44],\n",
       "       [716.33],\n",
       "       [729.21],\n",
       "       [744.61],\n",
       "       [756.59],\n",
       "       [772.34],\n",
       "       [785.82],\n",
       "       [798.2 ],\n",
       "       [811.96],\n",
       "       [824.59],\n",
       "       [837.33],\n",
       "       [846.33],\n",
       "       [855.39],\n",
       "       [865.81],\n",
       "       [872.36],\n",
       "       [877.63],\n",
       "       [884.24],\n",
       "       [889.54],\n",
       "       [890.87],\n",
       "       [892.2 ],\n",
       "       [896.2 ],\n",
       "       [896.2 ],\n",
       "       [892.2 ],\n",
       "       [890.87],\n",
       "       [886.89],\n",
       "       [885.56],\n",
       "       [880.26],\n",
       "       [874.99],\n",
       "       [871.05],\n",
       "       [867.12],\n",
       "       [860.59],\n",
       "       [855.39],\n",
       "       [850.21],\n",
       "       [843.75],\n",
       "       [837.33],\n",
       "       [832.22],\n",
       "       [825.85],\n",
       "       [816.99],\n",
       "       [810.7 ],\n",
       "       [801.93],\n",
       "       [794.47],\n",
       "       [785.82],\n",
       "       [777.22],\n",
       "       [768.68],\n",
       "       [758.99],\n",
       "       [748.19],\n",
       "       [737.47],\n",
       "       [728.03],\n",
       "       [715.16],\n",
       "       [702.44],\n",
       "       [692.13],\n",
       "       [677.42],\n",
       "       [664.  ],\n",
       "       [650.74],\n",
       "       [633.33],\n",
       "       [622.58],\n",
       "       [608.78],\n",
       "       [595.19],\n",
       "       [582.79],\n",
       "       [569.54],\n",
       "       [559.48],\n",
       "       [556.48],\n",
       "       [556.48],\n",
       "       [556.48],\n",
       "       [556.48],\n",
       "       [555.49],\n",
       "       [552.5 ],\n",
       "       [550.52],\n",
       "       [551.51],\n",
       "       [552.5 ],\n",
       "       [552.5 ],\n",
       "       [552.5 ],\n",
       "       [548.53],\n",
       "       [548.53],\n",
       "       [548.53],\n",
       "       [548.53],\n",
       "       [545.58],\n",
       "       [544.59],\n",
       "       [544.59],\n",
       "       [544.59],\n",
       "       [542.63],\n",
       "       [540.66],\n",
       "       [540.66],\n",
       "       [540.66],\n",
       "       [540.66],\n",
       "       [537.73],\n",
       "       [536.75],\n",
       "       [536.75],\n",
       "       [536.75],\n",
       "       [536.75],\n",
       "       [532.85],\n",
       "       [532.85],\n",
       "       [532.85],\n",
       "       [532.85],\n",
       "       [532.85],\n",
       "       [529.95],\n",
       "       [528.98],\n",
       "       [528.98],\n",
       "       [528.98],\n",
       "       [527.05],\n",
       "       [525.12],\n",
       "       [525.12],\n",
       "       [525.12],\n",
       "       [525.12],\n",
       "       [523.2 ],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [519.37],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [516.5 ],\n",
       "       [517.45],\n",
       "       [515.55],\n",
       "       [516.5 ],\n",
       "       [516.5 ],\n",
       "       [515.55],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [514.59],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [518.41],\n",
       "       [520.32],\n",
       "       [520.32],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [521.28],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [517.45],\n",
       "       [515.55],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [513.64],\n",
       "       [512.69],\n",
       "       [509.85],\n",
       "       [509.85],\n",
       "       [509.85],\n",
       "       [509.85],\n",
       "       [509.85],\n",
       "       [509.85],\n",
       "       [507.02],\n",
       "       [506.08],\n",
       "       [506.08],\n",
       "       [506.08],\n",
       "       [506.08],\n",
       "       [506.08],\n",
       "       [505.14],\n",
       "       [502.33],\n",
       "       [502.33],\n",
       "       [502.33],\n",
       "       [502.33],\n",
       "       [502.33],\n",
       "       [499.53],\n",
       "       [498.59],\n",
       "       [498.59],\n",
       "       [498.59],\n",
       "       [498.59],\n",
       "       [495.8 ],\n",
       "       [494.87],\n",
       "       [494.87],\n",
       "       [494.87],\n",
       "       [494.87],\n",
       "       [492.09],\n",
       "       [491.16],\n",
       "       [491.16],\n",
       "       [491.16],\n",
       "       [490.24],\n",
       "       [487.47],\n",
       "       [487.47],\n",
       "       [487.47],\n",
       "       [487.47],\n",
       "       [485.64],\n",
       "       [483.8 ],\n",
       "       [483.8 ],\n",
       "       [483.8 ],\n",
       "       [483.8 ],\n",
       "       [483.8 ],\n",
       "       [483.8 ],\n",
       "       [480.15],\n",
       "       [480.15],\n",
       "       [480.15],\n",
       "       [478.33],\n",
       "       [476.51],\n",
       "       [476.51],\n",
       "       [476.51],\n",
       "       [472.89],\n",
       "       [472.89],\n",
       "       [472.89],\n",
       "       [471.09],\n",
       "       [469.29],\n",
       "       [469.29],\n",
       "       [466.61],\n",
       "       [465.71],\n",
       "       [465.71],\n",
       "       [462.14],\n",
       "       [462.14],\n",
       "       [462.14],\n",
       "       [460.36],\n",
       "       [458.58],\n",
       "       [458.58],\n",
       "       [455.93],\n",
       "       [455.05],\n",
       "       [455.05],\n",
       "       [452.41],\n",
       "       [451.53],\n",
       "       [451.53],\n",
       "       [448.03],\n",
       "       [448.03],\n",
       "       [448.03],\n",
       "       [445.41],\n",
       "       [444.54],\n",
       "       [442.81],\n",
       "       [441.08],\n",
       "       [441.08],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [434.19],\n",
       "       [434.19],\n",
       "       [433.34],\n",
       "       [430.77],\n",
       "       [430.77],\n",
       "       [427.37],\n",
       "       [427.37],\n",
       "       [426.52],\n",
       "       [423.98],\n",
       "       [423.98],\n",
       "       [423.14],\n",
       "       [420.61],\n",
       "       [420.61],\n",
       "       [418.94],\n",
       "       [418.1 ],\n",
       "       [417.26],\n",
       "       [417.26],\n",
       "       [415.59],\n",
       "       [413.92],\n",
       "       [413.92],\n",
       "       [413.92],\n",
       "       [411.43],\n",
       "       [410.6 ],\n",
       "       [410.6 ],\n",
       "       [410.6 ],\n",
       "       [408.13],\n",
       "       [407.3 ],\n",
       "       [407.3 ],\n",
       "       [407.3 ],\n",
       "       [404.83],\n",
       "       [404.83],\n",
       "       [404.83],\n",
       "       [404.01],\n",
       "       [404.83],\n",
       "       [404.01],\n",
       "       [404.83],\n",
       "       [406.48],\n",
       "       [406.48],\n",
       "       [407.3 ],\n",
       "       [408.13],\n",
       "       [410.6 ],\n",
       "       [413.92],\n",
       "       [416.43],\n",
       "       [419.77],\n",
       "       [423.14],\n",
       "       [426.52],\n",
       "       [429.07],\n",
       "       [431.63],\n",
       "       [434.19],\n",
       "       [436.76],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [437.62],\n",
       "       [435.05],\n",
       "       [434.19],\n",
       "       [431.63],\n",
       "       [430.77],\n",
       "       [427.37],\n",
       "       [427.37],\n",
       "       [423.98],\n",
       "       [423.14],\n",
       "       [420.61],\n",
       "       [419.77],\n",
       "       [417.26],\n",
       "       [416.43],\n",
       "       [413.92],\n",
       "       [413.92],\n",
       "       [411.43],\n",
       "       [410.6 ],\n",
       "       [408.95],\n",
       "       [407.3 ],\n",
       "       [407.3 ],\n",
       "       [406.48],\n",
       "       [404.01],\n",
       "       [404.01],\n",
       "       [403.19],\n",
       "       [400.74],\n",
       "       [400.74],\n",
       "       [399.93],\n",
       "       [397.49],\n",
       "       [397.49],\n",
       "       [395.87],\n",
       "       [394.25],\n",
       "       [394.25],\n",
       "       [393.45],\n",
       "       [391.03],\n",
       "       [391.03],\n",
       "       [389.43],\n",
       "       [387.82],\n",
       "       [387.82],\n",
       "       [386.23],\n",
       "       [384.63],\n",
       "       [384.63],\n",
       "       [384.63],\n",
       "       [382.25],\n",
       "       [381.46],\n",
       "       [379.09],\n",
       "       [378.3 ],\n",
       "       [378.3 ],\n",
       "       [378.3 ],\n",
       "       [375.16],\n",
       "       [375.16],\n",
       "       [368.92],\n",
       "       [365.83],\n",
       "       [364.29],\n",
       "       [362.75],\n",
       "       [360.46],\n",
       "       [358.93],\n",
       "       [356.64],\n",
       "       [355.13],\n",
       "       [353.61],\n",
       "       [350.6 ],\n",
       "       [349.1 ],\n",
       "       [347.6 ],\n",
       "       [346.86],\n",
       "       [346.86],\n",
       "       [346.11],\n",
       "       [344.62],\n",
       "       [342.39],\n",
       "       [342.4 ],\n",
       "       [340.18],\n",
       "       [339.44],\n",
       "       [338.7 ],\n",
       "       [338.7 ],\n",
       "       [338.7 ],\n",
       "       [333.58],\n",
       "       [331.39],\n",
       "       [329.94],\n",
       "       [326.33],\n",
       "       [324.9 ],\n",
       "       [322.04],\n",
       "       [321.32],\n",
       "       [320.61],\n",
       "       [318.48],\n",
       "       [318.48],\n",
       "       [318.48],\n",
       "       [315.65],\n",
       "       [314.25],\n",
       "       [311.44],\n",
       "       [310.04],\n",
       "       [310.04],\n",
       "       [307.96],\n",
       "       [306.57],\n",
       "       [304.5 ],\n",
       "       [304.5 ],\n",
       "       [303.13],\n",
       "       [301.75],\n",
       "       [299.7 ],\n",
       "       [299.01],\n",
       "       [298.33],\n",
       "       [296.29],\n",
       "       [296.29],\n",
       "       [294.94],\n",
       "       [293.59],\n",
       "       [291.57],\n",
       "       [289.57],\n",
       "       [288.23],\n",
       "       [287.57],\n",
       "       [285.57],\n",
       "       [282.92],\n",
       "       [282.92],\n",
       "       [281.61],\n",
       "       [280.3 ],\n",
       "       [278.99],\n",
       "       [280.3 ],\n",
       "       [278.34],\n",
       "       [278.34],\n",
       "       [276.38],\n",
       "       [275.08],\n",
       "       [273.79],\n",
       "       [272.5 ],\n",
       "       [270.57],\n",
       "       [269.93],\n",
       "       [269.93],\n",
       "       [267.38],\n",
       "       [266.75],\n",
       "       [264.84],\n",
       "       [262.94],\n",
       "       [262.31],\n",
       "       [261.06],\n",
       "       [260.43],\n",
       "       [259.8 ],\n",
       "       [258.56],\n",
       "       [256.69],\n",
       "       [254.83],\n",
       "       [253.6 ],\n",
       "       [252.36],\n",
       "       [249.91],\n",
       "       [249.91],\n",
       "       [249.91],\n",
       "       [249.91],\n",
       "       [248.7 ],\n",
       "       [247.48],\n",
       "       [245.67],\n",
       "       [245.06],\n",
       "       [242.65],\n",
       "       [242.65],\n",
       "       [242.05],\n",
       "       [240.26],\n",
       "       [239.67],\n",
       "       [237.88],\n",
       "       [237.88],\n",
       "       [235.52],\n",
       "       [235.52],\n",
       "       [233.17],\n",
       "       [233.17],\n",
       "       [232.  ],\n",
       "       [230.83],\n",
       "       [230.83],\n",
       "       [230.83],\n",
       "       [230.25],\n",
       "       [229.09],\n",
       "       [228.51],\n",
       "       [226.21],\n",
       "       [226.21],\n",
       "       [226.21],\n",
       "       [226.21],\n",
       "       [226.21],\n",
       "       [225.07],\n",
       "       [223.92],\n",
       "       [223.92],\n",
       "       [221.64],\n",
       "       [221.64],\n",
       "       [219.38],\n",
       "       [219.38],\n",
       "       [219.38],\n",
       "       [218.82],\n",
       "       [217.69],\n",
       "       [217.13],\n",
       "       [214.89],\n",
       "       [214.89],\n",
       "       [212.67],\n",
       "       [212.67],\n",
       "       [211.02],\n",
       "       [210.47],\n",
       "       [209.37],\n",
       "       [208.27],\n",
       "       [208.27],\n",
       "       [209.92],\n",
       "       [208.27],\n",
       "       [207.19],\n",
       "       [205.56],\n",
       "       [203.93],\n",
       "       [205.02],\n",
       "       [203.93],\n",
       "       [202.86],\n",
       "       [201.78],\n",
       "       [201.78],\n",
       "       [200.71],\n",
       "       [200.71],\n",
       "       [199.64],\n",
       "       [199.64],\n",
       "       [199.64],\n",
       "       [198.05],\n",
       "       [196.47],\n",
       "       [195.41],\n",
       "       [195.41],\n",
       "       [194.89],\n",
       "       [193.84],\n",
       "       [193.32],\n",
       "       [193.32],\n",
       "       [191.24],\n",
       "       [191.24],\n",
       "       [191.24],\n",
       "       [191.24],\n",
       "       [189.17],\n",
       "       [187.12],\n",
       "       [187.12],\n",
       "       [187.12],\n",
       "       [186.61],\n",
       "       [185.08],\n",
       "       [183.05],\n",
       "       [182.55],\n",
       "       [182.05],\n",
       "       [181.04],\n",
       "       [181.04],\n",
       "       [180.54],\n",
       "       [179.04],\n",
       "       [178.05],\n",
       "       [178.55],\n",
       "       [177.06],\n",
       "       [177.06],\n",
       "       [177.06],\n",
       "       [177.06],\n",
       "       [175.09],\n",
       "       [175.09],\n",
       "       [174.6 ],\n",
       "       [173.13],\n",
       "       [173.13],\n",
       "       [171.18],\n",
       "       [171.18],\n",
       "       [169.25],\n",
       "       [169.25],\n",
       "       [169.25],\n",
       "       [165.91],\n",
       "       [164.96],\n",
       "       [165.43],\n",
       "       [164.49],\n",
       "       [163.54],\n",
       "       [163.54],\n",
       "       [163.07],\n",
       "       [161.66],\n",
       "       [161.66],\n",
       "       [161.66],\n",
       "       [160.73],\n",
       "       [159.8 ],\n",
       "       [159.8 ],\n",
       "       [159.8 ],\n",
       "       [159.8 ],\n",
       "       [158.88],\n",
       "       [157.95],\n",
       "       [157.95],\n",
       "       [156.11],\n",
       "       [156.11],\n",
       "       [155.65],\n",
       "       [154.28],\n",
       "       [153.83],\n",
       "       [152.47],\n",
       "       [152.47],\n",
       "       [152.47],\n",
       "       [151.12],\n",
       "       [150.67],\n",
       "       [150.23],\n",
       "       [149.78],\n",
       "       [149.34],\n",
       "       [148.89],\n",
       "       [148.89],\n",
       "       [148.  ],\n",
       "       [147.11],\n",
       "       [147.11],\n",
       "       [147.11],\n",
       "       [146.23],\n",
       "       [145.35],\n",
       "       [145.35],\n",
       "       [143.61],\n",
       "       [143.61],\n",
       "       [143.61],\n",
       "       [142.31],\n",
       "       [141.87],\n",
       "       [141.87],\n",
       "       [141.44],\n",
       "       [140.15],\n",
       "       [140.15],\n",
       "       [139.3 ],\n",
       "       [138.45],\n",
       "       [138.45],\n",
       "       [137.18],\n",
       "       [136.75],\n",
       "       [136.75],\n",
       "       [136.75],\n",
       "       [136.33],\n",
       "       [135.07],\n",
       "       [135.07],\n",
       "       [135.07],\n",
       "       [135.07],\n",
       "       [133.82],\n",
       "       [133.4 ],\n",
       "       [133.4 ],\n",
       "       [133.4 ],\n",
       "       [132.99],\n",
       "       [131.74],\n",
       "       [131.74],\n",
       "       [131.74],\n",
       "       [131.74],\n",
       "       [130.1 ],\n",
       "       [130.1 ],\n",
       "       [130.1 ],\n",
       "       [130.1 ],\n",
       "       [130.1 ],\n",
       "       [129.29],\n",
       "       [128.47],\n",
       "       [128.47],\n",
       "       [128.07],\n",
       "       [126.85],\n",
       "       [126.85],\n",
       "       [126.45],\n",
       "       [126.85],\n",
       "       [125.24],\n",
       "       [125.24],\n",
       "       [125.24],\n",
       "       [124.84],\n",
       "       [123.65],\n",
       "       [123.65],\n",
       "       [122.06],\n",
       "       [122.06],\n",
       "       [122.06],\n",
       "       [121.67],\n",
       "       [120.5 ],\n",
       "       [120.5 ],\n",
       "       [120.11],\n",
       "       [118.94],\n",
       "       [118.94],\n",
       "       [118.94],\n",
       "       [117.78],\n",
       "       [117.39],\n",
       "       [117.39],\n",
       "       [117.39],\n",
       "       [117.39],\n",
       "       [117.39],\n",
       "       [116.24],\n",
       "       [115.86],\n",
       "       [115.86]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 30*24\n",
    "np.array(flow_df.iloc[7000:7001+window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105.84,\n",
       " 107.3,\n",
       " 108.76,\n",
       " 109.86,\n",
       " 110.6,\n",
       " 111.34,\n",
       " 111.34,\n",
       " 111.34,\n",
       " 112.84,\n",
       " 113.97,\n",
       " 115.48,\n",
       " 117.4,\n",
       " 120.11,\n",
       " 122.86,\n",
       " 126.05,\n",
       " 129.7,\n",
       " 134.24,\n",
       " 138.45,\n",
       " 142.31,\n",
       " 145.79,\n",
       " 150.68,\n",
       " 155.66,\n",
       " 159.8,\n",
       " 164.01,\n",
       " 169.25,\n",
       " 175.09,\n",
       " 180.54,\n",
       " 186.61,\n",
       " 192.8,\n",
       " 199.12,\n",
       " 205.02,\n",
       " 211.02,\n",
       " 216.57,\n",
       " 222.22,\n",
       " 228.52,\n",
       " 237.34,\n",
       " 309.1,\n",
       " 480.25,\n",
       " 603.53,\n",
       " 619.39,\n",
       " 632.24,\n",
       " 646.36,\n",
       " 659.56,\n",
       " 675.17,\n",
       " 687.59,\n",
       " 702.44,\n",
       " 716.33,\n",
       " 729.21,\n",
       " 744.61,\n",
       " 756.59,\n",
       " 772.34,\n",
       " 785.82,\n",
       " 798.2,\n",
       " 811.96,\n",
       " 824.59,\n",
       " 837.33,\n",
       " 846.33,\n",
       " 855.39,\n",
       " 865.81,\n",
       " 872.36,\n",
       " 877.63,\n",
       " 884.24,\n",
       " 889.54,\n",
       " 890.87,\n",
       " 892.2,\n",
       " 896.2,\n",
       " 896.2,\n",
       " 892.2,\n",
       " 890.87,\n",
       " 886.89,\n",
       " 885.56,\n",
       " 880.26,\n",
       " 874.99,\n",
       " 871.05,\n",
       " 867.12,\n",
       " 860.59,\n",
       " 855.39,\n",
       " 850.21,\n",
       " 843.75,\n",
       " 837.33,\n",
       " 832.22,\n",
       " 825.85,\n",
       " 816.99,\n",
       " 810.7,\n",
       " 801.93,\n",
       " 794.47,\n",
       " 785.82,\n",
       " 777.22,\n",
       " 768.68,\n",
       " 758.99,\n",
       " 748.19,\n",
       " 737.47,\n",
       " 728.03,\n",
       " 715.16,\n",
       " 702.44,\n",
       " 692.13,\n",
       " 677.42,\n",
       " 664.0,\n",
       " 650.74,\n",
       " 633.33,\n",
       " 622.58,\n",
       " 608.78,\n",
       " 595.19,\n",
       " 582.79,\n",
       " 569.54,\n",
       " 559.48,\n",
       " 556.48,\n",
       " 556.48,\n",
       " 556.48,\n",
       " 556.48,\n",
       " 555.49,\n",
       " 552.5,\n",
       " 550.52,\n",
       " 551.51,\n",
       " 552.5,\n",
       " 552.5,\n",
       " 552.5,\n",
       " 548.53,\n",
       " 548.53,\n",
       " 548.53,\n",
       " 548.53,\n",
       " 545.58,\n",
       " 544.59,\n",
       " 544.59,\n",
       " 544.59,\n",
       " 542.63,\n",
       " 540.66,\n",
       " 540.66,\n",
       " 540.66,\n",
       " 540.66,\n",
       " 537.73,\n",
       " 536.75,\n",
       " 536.75,\n",
       " 536.75,\n",
       " 536.75,\n",
       " 532.85,\n",
       " 532.85,\n",
       " 532.85,\n",
       " 532.85,\n",
       " 532.85,\n",
       " 529.95,\n",
       " 528.98,\n",
       " 528.98,\n",
       " 528.98,\n",
       " 527.05,\n",
       " 525.12,\n",
       " 525.12,\n",
       " 525.12,\n",
       " 525.12,\n",
       " 523.2,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 519.37,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 516.5,\n",
       " 517.45,\n",
       " 515.55,\n",
       " 516.5,\n",
       " 516.5,\n",
       " 515.55,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 514.59,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 518.41,\n",
       " 520.32,\n",
       " 520.32,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 521.28,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 517.45,\n",
       " 515.55,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 513.64,\n",
       " 512.69,\n",
       " 509.85,\n",
       " 509.85,\n",
       " 509.85,\n",
       " 509.85,\n",
       " 509.85,\n",
       " 509.85,\n",
       " 507.02,\n",
       " 506.08,\n",
       " 506.08,\n",
       " 506.08,\n",
       " 506.08,\n",
       " 506.08,\n",
       " 505.14,\n",
       " 502.33,\n",
       " 502.33,\n",
       " 502.33,\n",
       " 502.33,\n",
       " 502.33,\n",
       " 499.53,\n",
       " 498.59,\n",
       " 498.59,\n",
       " 498.59,\n",
       " 498.59,\n",
       " 495.8,\n",
       " 494.87,\n",
       " 494.87,\n",
       " 494.87,\n",
       " 494.87,\n",
       " 492.09,\n",
       " 491.16,\n",
       " 491.16,\n",
       " 491.16,\n",
       " 490.24,\n",
       " 487.47,\n",
       " 487.47,\n",
       " 487.47,\n",
       " 487.47,\n",
       " 485.64,\n",
       " 483.8,\n",
       " 483.8,\n",
       " 483.8,\n",
       " 483.8,\n",
       " 483.8,\n",
       " 483.8,\n",
       " 480.15,\n",
       " 480.15,\n",
       " 480.15,\n",
       " 478.33,\n",
       " 476.51,\n",
       " 476.51,\n",
       " 476.51,\n",
       " 472.89,\n",
       " 472.89,\n",
       " 472.89,\n",
       " 471.09,\n",
       " 469.29,\n",
       " 469.29,\n",
       " 466.61,\n",
       " 465.71,\n",
       " 465.71,\n",
       " 462.14,\n",
       " 462.14,\n",
       " 462.14,\n",
       " 460.36,\n",
       " 458.58,\n",
       " 458.58,\n",
       " 455.93,\n",
       " 455.05,\n",
       " 455.05,\n",
       " 452.41,\n",
       " 451.53,\n",
       " 451.53,\n",
       " 448.03,\n",
       " 448.03,\n",
       " 448.03,\n",
       " 445.41,\n",
       " 444.54,\n",
       " 442.81,\n",
       " 441.08,\n",
       " 441.08,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 434.19,\n",
       " 434.19,\n",
       " 433.34,\n",
       " 430.77,\n",
       " 430.77,\n",
       " 427.37,\n",
       " 427.37,\n",
       " 426.52,\n",
       " 423.98,\n",
       " 423.98,\n",
       " 423.14,\n",
       " 420.61,\n",
       " 420.61,\n",
       " 418.94,\n",
       " 418.1,\n",
       " 417.26,\n",
       " 417.26,\n",
       " 415.59,\n",
       " 413.92,\n",
       " 413.92,\n",
       " 413.92,\n",
       " 411.43,\n",
       " 410.6,\n",
       " 410.6,\n",
       " 410.6,\n",
       " 408.13,\n",
       " 407.3,\n",
       " 407.3,\n",
       " 407.3,\n",
       " 404.83,\n",
       " 404.83,\n",
       " 404.83,\n",
       " 404.01,\n",
       " 404.83,\n",
       " 404.01,\n",
       " 404.83,\n",
       " 406.48,\n",
       " 406.48,\n",
       " 407.3,\n",
       " 408.13,\n",
       " 410.6,\n",
       " 413.92,\n",
       " 416.43,\n",
       " 419.77,\n",
       " 423.14,\n",
       " 426.52,\n",
       " 429.07,\n",
       " 431.63,\n",
       " 434.19,\n",
       " 436.76,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 437.62,\n",
       " 435.05,\n",
       " 434.19,\n",
       " 431.63,\n",
       " 430.77,\n",
       " 427.37,\n",
       " 427.37,\n",
       " 423.98,\n",
       " 423.14,\n",
       " 420.61,\n",
       " 419.77,\n",
       " 417.26,\n",
       " 416.43,\n",
       " 413.92,\n",
       " 413.92,\n",
       " 411.43,\n",
       " 410.6,\n",
       " 408.95,\n",
       " 407.3,\n",
       " 407.3,\n",
       " 406.48,\n",
       " 404.01,\n",
       " 404.01,\n",
       " 403.19,\n",
       " 400.74,\n",
       " 400.74,\n",
       " 399.93,\n",
       " 397.49,\n",
       " 397.49,\n",
       " 395.87,\n",
       " 394.25,\n",
       " 394.25,\n",
       " 393.45,\n",
       " 391.03,\n",
       " 391.03,\n",
       " 389.43,\n",
       " 387.82,\n",
       " 387.82,\n",
       " 386.23,\n",
       " 384.63,\n",
       " 384.63,\n",
       " 384.63,\n",
       " 382.25,\n",
       " 381.46,\n",
       " 379.09,\n",
       " 378.3,\n",
       " 378.3,\n",
       " 378.3,\n",
       " 375.16,\n",
       " 375.16,\n",
       " 368.92,\n",
       " 365.83,\n",
       " 364.29,\n",
       " 362.75,\n",
       " 360.46,\n",
       " 358.93,\n",
       " 356.64,\n",
       " 355.13,\n",
       " 353.61,\n",
       " 350.6,\n",
       " 349.1,\n",
       " 347.6,\n",
       " 346.86,\n",
       " 346.86,\n",
       " 346.11,\n",
       " 344.62,\n",
       " 342.39,\n",
       " 342.4,\n",
       " 340.18,\n",
       " 339.44,\n",
       " 338.7,\n",
       " 338.7,\n",
       " 338.7,\n",
       " 333.58,\n",
       " 331.39,\n",
       " 329.94,\n",
       " 326.33,\n",
       " 324.9,\n",
       " 322.04,\n",
       " 321.32,\n",
       " 320.61,\n",
       " 318.48,\n",
       " 318.48,\n",
       " 318.48,\n",
       " 315.65,\n",
       " 314.25,\n",
       " 311.44,\n",
       " 310.04,\n",
       " 310.04,\n",
       " 307.96,\n",
       " 306.57,\n",
       " 304.5,\n",
       " 304.5,\n",
       " 303.13,\n",
       " 301.75,\n",
       " 299.7,\n",
       " 299.01,\n",
       " 298.33,\n",
       " 296.29,\n",
       " 296.29,\n",
       " 294.94,\n",
       " 293.59,\n",
       " 291.57,\n",
       " 289.57,\n",
       " 288.23,\n",
       " 287.57,\n",
       " 285.57,\n",
       " 282.92,\n",
       " 282.92,\n",
       " 281.61,\n",
       " 280.3,\n",
       " 278.99,\n",
       " 280.3,\n",
       " 278.34,\n",
       " 278.34,\n",
       " 276.38,\n",
       " 275.08,\n",
       " 273.79,\n",
       " 272.5,\n",
       " 270.57,\n",
       " 269.93,\n",
       " 269.93,\n",
       " 267.38,\n",
       " 266.75,\n",
       " 264.84,\n",
       " 262.94,\n",
       " 262.31,\n",
       " 261.06,\n",
       " 260.43,\n",
       " 259.8,\n",
       " 258.56,\n",
       " 256.69,\n",
       " 254.83,\n",
       " 253.6,\n",
       " 252.36,\n",
       " 249.91,\n",
       " 249.91,\n",
       " 249.91,\n",
       " 249.91,\n",
       " 248.7,\n",
       " 247.48,\n",
       " 245.67,\n",
       " 245.06,\n",
       " 242.65,\n",
       " 242.65,\n",
       " 242.05,\n",
       " 240.26,\n",
       " 239.67,\n",
       " 237.88,\n",
       " 237.88,\n",
       " 235.52,\n",
       " 235.52,\n",
       " 233.17,\n",
       " 233.17,\n",
       " 232.0,\n",
       " 230.83,\n",
       " 230.83,\n",
       " 230.83,\n",
       " 230.25,\n",
       " 229.09,\n",
       " 228.51,\n",
       " 226.21,\n",
       " 226.21,\n",
       " 226.21,\n",
       " 226.21,\n",
       " 226.21,\n",
       " 225.07,\n",
       " 223.92,\n",
       " 223.92,\n",
       " 221.64,\n",
       " 221.64,\n",
       " 219.38,\n",
       " 219.38,\n",
       " 219.38,\n",
       " 218.82,\n",
       " 217.69,\n",
       " 217.13,\n",
       " 214.89,\n",
       " 214.89,\n",
       " 212.67,\n",
       " 212.67,\n",
       " 211.02,\n",
       " 210.47,\n",
       " 209.37,\n",
       " 208.27,\n",
       " 208.27,\n",
       " 209.92,\n",
       " 208.27,\n",
       " 207.19,\n",
       " 205.56,\n",
       " 203.93,\n",
       " 205.02,\n",
       " 203.93,\n",
       " 202.86,\n",
       " 201.78,\n",
       " 201.78,\n",
       " 200.71,\n",
       " 200.71,\n",
       " 199.64,\n",
       " 199.64,\n",
       " 199.64,\n",
       " 198.05,\n",
       " 196.47,\n",
       " 195.41,\n",
       " 195.41,\n",
       " 194.89,\n",
       " 193.84,\n",
       " 193.32,\n",
       " 193.32,\n",
       " 191.24,\n",
       " 191.24,\n",
       " 191.24,\n",
       " 191.24,\n",
       " 189.17,\n",
       " 187.12,\n",
       " 187.12,\n",
       " 187.12,\n",
       " 186.61,\n",
       " 185.08,\n",
       " 183.05,\n",
       " 182.55,\n",
       " 182.05,\n",
       " 181.04,\n",
       " 181.04,\n",
       " 180.54,\n",
       " 179.04,\n",
       " 178.05,\n",
       " 178.55,\n",
       " 177.06,\n",
       " 177.06,\n",
       " 177.06,\n",
       " 177.06,\n",
       " 175.09,\n",
       " 175.09,\n",
       " 174.6,\n",
       " 173.13,\n",
       " 173.13,\n",
       " 171.18,\n",
       " 171.18,\n",
       " 169.25,\n",
       " 169.25,\n",
       " 169.25,\n",
       " 165.91,\n",
       " 164.96,\n",
       " 165.43,\n",
       " 164.49,\n",
       " 163.54,\n",
       " 163.54,\n",
       " 163.07,\n",
       " 161.66,\n",
       " 161.66,\n",
       " 161.66,\n",
       " 160.73,\n",
       " 159.8,\n",
       " 159.8,\n",
       " 159.8,\n",
       " 159.8,\n",
       " 158.88,\n",
       " 157.95,\n",
       " 157.95,\n",
       " 156.11,\n",
       " 156.11,\n",
       " 155.65,\n",
       " 154.28,\n",
       " 153.83,\n",
       " 152.47,\n",
       " 152.47,\n",
       " 152.47,\n",
       " 151.12,\n",
       " 150.67,\n",
       " 150.23,\n",
       " 149.78,\n",
       " 149.34,\n",
       " 148.89,\n",
       " 148.89,\n",
       " 148.0,\n",
       " 147.11,\n",
       " 147.11,\n",
       " 147.11,\n",
       " 146.23,\n",
       " 145.35,\n",
       " 145.35,\n",
       " 143.61,\n",
       " 143.61,\n",
       " 143.61,\n",
       " 142.31,\n",
       " 141.87,\n",
       " 141.87,\n",
       " 141.44,\n",
       " 140.15,\n",
       " 140.15,\n",
       " 139.3,\n",
       " 138.45,\n",
       " 138.45,\n",
       " 137.18,\n",
       " 136.75,\n",
       " 136.75,\n",
       " 136.75,\n",
       " 136.33,\n",
       " 135.07,\n",
       " 135.07,\n",
       " 135.07,\n",
       " 135.07,\n",
       " 133.82,\n",
       " 133.4,\n",
       " 133.4,\n",
       " 133.4,\n",
       " 132.99,\n",
       " 131.74,\n",
       " 131.74,\n",
       " 131.74,\n",
       " 131.74,\n",
       " 130.1,\n",
       " 130.1,\n",
       " 130.1,\n",
       " 130.1,\n",
       " 130.1,\n",
       " 129.29,\n",
       " 128.47,\n",
       " 128.47,\n",
       " 128.07,\n",
       " 126.85,\n",
       " 126.85,\n",
       " 126.45,\n",
       " 126.85,\n",
       " 125.24,\n",
       " 125.24,\n",
       " 125.24,\n",
       " 124.84,\n",
       " 123.65,\n",
       " 123.65,\n",
       " 122.06,\n",
       " 122.06,\n",
       " 122.06,\n",
       " 121.67,\n",
       " 120.5,\n",
       " 120.5,\n",
       " 120.11,\n",
       " 118.94,\n",
       " 118.94,\n",
       " 118.94,\n",
       " 117.78,\n",
       " 117.39,\n",
       " 117.39,\n",
       " 117.39,\n",
       " 117.39,\n",
       " 117.39,\n",
       " 116.24,\n",
       " 115.86,\n",
       " 115.86]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.squeeze(np.array(flow_df.iloc[7000:7001+window])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 2) (5, 2)\n",
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]]\n",
      "[[10 15]\n",
      " [20 25]\n",
      " [30 35]] [ 85 105]\n",
      "[[20 25]\n",
      " [30 35]\n",
      " [40 45]] [105 125]\n",
      "[[30 35]\n",
      " [40 45]\n",
      " [50 55]] [125 145]\n",
      "[[40 45]\n",
      " [50 55]\n",
      " [60 65]] [145 165]\n",
      "[[50 55]\n",
      " [60 65]\n",
      " [70 75]] [165 185]\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step data preparation\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix:out_end_ix, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "print(dataset)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix:out_end_ix, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([flow_df, rain_df, et_df, flow_df], axis=1)\n",
    "dataset.columns = ['flow', 'rain', 'et', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "      <th>rain</th>\n",
       "      <th>et</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.80</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>159.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>158.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>157.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156.11</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>156.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.28</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>154.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25949</th>\n",
       "      <td>183.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>183.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25950</th>\n",
       "      <td>181.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>181.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25951</th>\n",
       "      <td>181.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>181.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25952</th>\n",
       "      <td>181.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>181.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25953</th>\n",
       "      <td>180.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1480</td>\n",
       "      <td>180.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25954 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         flow  rain      et       y\n",
       "0      159.80   3.6  0.0555  159.80\n",
       "1      158.41   2.6  0.0555  158.41\n",
       "2      157.49   1.0  0.0555  157.49\n",
       "3      156.11   1.2  0.0555  156.11\n",
       "4      154.28   5.6  0.0555  154.28\n",
       "...       ...   ...     ...     ...\n",
       "25949  183.05   0.0  0.1480  183.05\n",
       "25950  181.04   0.0  0.1480  181.04\n",
       "25951  181.04   0.0  0.1480  181.04\n",
       "25952  181.04   0.0  0.1480  181.04\n",
       "25953  180.54   0.0  0.1480  180.54\n",
       "\n",
       "[25954 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window without NA (17487, 18718) after that i could try (6078, 17486)\n",
    "to_split = np.array(dataset.iloc[17487:18718, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps_in = 24*30   #24 hours, 30 days\n",
    "n_steps_out = 24*7   #24 hours, 7 days\n",
    "\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='sigmoid', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(128, activation='sigmoid'))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 8s 745ms/step - loss: 1917.8132\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 8s 757ms/step - loss: 1811.3824\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 8s 760ms/step - loss: 1673.3735\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 1534.2856\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 1410.4071\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 1294.5298\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 1188.9178\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 1091.3947\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 1002.6118\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 9s 816ms/step - loss: 916.4674\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 9s 826ms/step - loss: 839.6967\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 9s 810ms/step - loss: 769.9505\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 704.7914\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 9s 816ms/step - loss: 645.1787\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 590.4009\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 9s 811ms/step - loss: 539.7908\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 9s 809ms/step - loss: 493.1013\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 9s 841ms/step - loss: 450.3665\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 9s 809ms/step - loss: 411.2981\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 9s 842ms/step - loss: 374.9477\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 342.0908\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 9s 826ms/step - loss: 311.9326\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 9s 822ms/step - loss: 284.5271\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 259.5408\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 10s 879ms/step - loss: 236.8553\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 216.1136\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 197.4390\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 180.5931\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 9s 826ms/step - loss: 165.1406\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 9s 828ms/step - loss: 151.5664\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 139.0519\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 9s 840ms/step - loss: 127.9594\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 9s 836ms/step - loss: 118.1727\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 109.2531\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 101.4268\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 10s 877ms/step - loss: 94.2726\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 88.1133\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 9s 802ms/step - loss: 82.5430\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 77.7068\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 9s 823ms/step - loss: 73.3953\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 10s 877ms/step - loss: 69.6223\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 9s 795ms/step - loss: 66.3487\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 9s 841ms/step - loss: 63.3618\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 9s 791ms/step - loss: 60.8467\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 9s 836ms/step - loss: 58.7094\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 9s 804ms/step - loss: 56.7255\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 55.0380\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 9s 813ms/step - loss: 53.5059\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 52.3508\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 51.1895\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 9s 849ms/step - loss: 50.2957\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 9s 842ms/step - loss: 49.3918\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 9s 837ms/step - loss: 48.7710\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 48.1769\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 9s 859ms/step - loss: 47.6580\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 9s 844ms/step - loss: 47.2031\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 10s 928ms/step - loss: 46.8384\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 46.5527\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 46.2379\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 9s 815ms/step - loss: 46.0278\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 9s 845ms/step - loss: 45.8412\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 45.6468\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 9s 859ms/step - loss: 45.5459\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 9s 805ms/step - loss: 45.4110\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 9s 846ms/step - loss: 45.3454\n",
      "Epoch 66/200\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 32.5130"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-17e32cf1a20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[70, 75],\n",
       "        [80, 85],\n",
       "        [90, 95]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = np.array([[70, 75], [80, 85], [90, 95]])\n",
    "x_input = x_input.reshape((1, 3, 2))\n",
    "x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>159.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>158.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y\n",
       "0  159.80\n",
       "1  158.41\n",
       "2  157.49\n",
       "3  156.11\n",
       "4  154.28"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0:5, 3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(dataset.iloc[18741:23437, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(dataset.iloc[18741:23437, 3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[0:n_steps_in].reshape((1, n_steps_in, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(x_test, verbose=0)\n",
    "len(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test[n_steps_in:n_steps_in+n_steps_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc0dc09c9d0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09ca30>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09cbb0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09cc70>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09cd30>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09cdf0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09ceb0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc09cf70>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9070>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9130>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0efc10>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9250>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a94c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a97c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9a00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9ac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9b80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9c40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9d00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9dc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9e80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9f40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0a9fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b01c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b04c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b07c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0a00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0ac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0b80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0c40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0d00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0dc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0e80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0f40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b0fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b71c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b74c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b77c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7a00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7ac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7b80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7c40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7d00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7dc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7e80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7f40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0b7fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e1c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e4c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e7c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03e940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03ea00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03eac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03eb80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03ec40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03ed00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03edc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03ee80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03ef40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc03efa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0451c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0454c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0457c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045a00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045ac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045b80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045c40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045d00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045dc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045e80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045f40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc045fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b1c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b4c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b7c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04b940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04ba00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bb80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bc40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bd00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bdc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04be80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bf40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc04bfa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0511c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0514c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0517c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051940>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051a00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051ac0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051b80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051c40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051d00>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051dc0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051e80>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051f40>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc051fa0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058100>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0581c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058280>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058340>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058400>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0584c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058580>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058640>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc0587c0>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058880>,\n",
       " <matplotlib.lines.Line2D at 0x7fc0dc058940>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc1640441c0>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(yhat[0])\n",
    "plt.plot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
