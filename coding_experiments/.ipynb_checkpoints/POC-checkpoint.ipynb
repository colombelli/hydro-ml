{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cleb_df_into_wal_df(cleb_df):\n",
    "    \n",
    "    index_names = {}\n",
    "    for i, (_, row) in enumerate(cleb_df.iterrows()):\n",
    "        \n",
    "        year = str(int(row[2]))\n",
    "        month = str(int(row[1]))\n",
    "        day = str(int(row[0]))\n",
    "        hour = str(int(row[3]))\n",
    "        index_name = year+'-'+month+'-'+day+'-'+hour\n",
    "        \n",
    "        index_names[i] = index_name\n",
    "        \n",
    "    \n",
    "    cleb_df.rename(index=index_names)\n",
    "    cleb_df = cleb_df.drop('day', 1)\n",
    "    cleb_df = cleb_df.drop('month', 1)\n",
    "    cleb_df = cleb_df.drop('year', 1)\n",
    "    cleb_df = cleb_df.drop('hour', 1)\n",
    "    return cleb_df.replace(-1, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow_path = \"/home/colombelli/Documents/hydro-ml/data/Vazao.txt\"\n",
    "rain_path = \"/home/colombelli/Documents/hydro-ml/data/Chuva.txt\"\n",
    "et_path = \"/home/colombelli/Documents/hydro-ml/data/ET.txt\"\n",
    "\n",
    "flow_df = pd.read_csv(flow_path, sep=\"\\t\", header=None)\n",
    "flow_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"flow\"]\n",
    "\n",
    "rain_df = pd.read_csv(rain_path, sep=\"\\t\", header=None)\n",
    "rain_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"rain\"]\n",
    "\n",
    "et_df = pd.read_csv(et_path, sep=\"\\t\", header=None)\n",
    "et_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"et\"]\n",
    "\n",
    "\n",
    "flow_df = transform_cleb_df_into_wal_df(flow_df)\n",
    "rain_df = transform_cleb_df_into_wal_df(rain_df)\n",
    "et_df = transform_cleb_df_into_wal_df(et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix], sequences[end_ix:out_end_ix, 0]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([flow_df, rain_df, et_df], axis=1)\n",
    "dataset.columns = ['flow', 'rain', 'et']\n",
    "\n",
    "n_steps_in = 48\n",
    "n_steps_out = 24\n",
    "\n",
    "to_split = np.array(dataset.iloc[6078:17486, ])   # get 14086 to 17486 for testing\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, \n",
    "               activation='sigmoid',\n",
    "               input_shape=(n_steps_in, n_features)))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "122/355 [=========>....................] - ETA: 56s - loss: 267906.1875"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
