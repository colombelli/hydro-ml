{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cleb_df_into_wal_df(cleb_df):\n",
    "    \n",
    "    index_names = {}\n",
    "    for i, (_, row) in enumerate(cleb_df.iterrows()):\n",
    "        \n",
    "        year = str(int(row[2]))\n",
    "        month = str(int(row[1]))\n",
    "        day = str(int(row[0]))\n",
    "        hour = str(int(row[3]))\n",
    "        index_name = year+'-'+month+'-'+day+'-'+hour\n",
    "        \n",
    "        index_names[i] = index_name\n",
    "        \n",
    "    \n",
    "    cleb_df.rename(index=index_names)\n",
    "    cleb_df = cleb_df.drop('day', 1)\n",
    "    cleb_df = cleb_df.drop('month', 1)\n",
    "    cleb_df = cleb_df.drop('year', 1)\n",
    "    cleb_df = cleb_df.drop('hour', 1)\n",
    "    return cleb_df.replace(-1, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flow_path = \"/home/colombelli/Documents/hydro-ml/data/Vazao.txt\"\n",
    "rain_path = \"/home/colombelli/Documents/hydro-ml/data/Chuva.txt\"\n",
    "et_path = \"/home/colombelli/Documents/hydro-ml/data/ET.txt\"\n",
    "\n",
    "flow_df = pd.read_csv(flow_path, sep=\"\\t\", header=None)\n",
    "flow_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"flow\"]\n",
    "\n",
    "rain_df = pd.read_csv(rain_path, sep=\"\\t\", header=None)\n",
    "rain_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"rain\"]\n",
    "\n",
    "et_df = pd.read_csv(et_path, sep=\"\\t\", header=None)\n",
    "et_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"et\"]\n",
    "\n",
    "\n",
    "flow_df = transform_cleb_df_into_wal_df(flow_df)\n",
    "rain_df = transform_cleb_df_into_wal_df(rain_df)\n",
    "et_df = transform_cleb_df_into_wal_df(et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        \n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "            \n",
    "        flow_et = sequences[i:end_ix, 0:2]\n",
    "        future_rain = sequences[end_ix:out_end_ix, 2:3]\n",
    "        future_flow = sequences[end_ix:out_end_ix, 0]\n",
    "        \n",
    "        seq_x = np.concatenate((flow_et, future_rain), axis=1)\n",
    "        seq_y = future_flow\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nash(observed, modeled):\n",
    "    \n",
    "    mean_obs = np.mean(observed)\n",
    "    \n",
    "    variance = 0 \n",
    "    squared_err = 0\n",
    "    for t, obs_flow in enumerate(observed):\n",
    "        squared_err += (modeled[t] - obs_flow) ** 2\n",
    "        variance += (obs_flow - mean_obs) ** 2\n",
    "        \n",
    "    nash = 1 - (squared_err  / variance)\n",
    "    return nash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([flow_df, et_df,rain_df], axis=1)\n",
    "dataset.columns = ['flow', 'et', 'rain']\n",
    "\n",
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "\n",
    "to_split = np.array(dataset.iloc[6078:17486, ])   # get 14086 to 17486 for testing\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)\n",
    "\n",
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, \n",
    "               activation='sigmoid',\n",
    "               input_shape=(n_steps_in, n_features)))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 259837.5625\n",
      "Epoch 2/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 200812.5156\n",
      "Epoch 3/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 163557.8125\n",
      "Epoch 4/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 137726.6094\n",
      "Epoch 5/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 118382.6250\n",
      "Epoch 6/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 102156.5625\n",
      "Epoch 7/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 88382.4766\n",
      "Epoch 8/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 76755.3203\n",
      "Epoch 9/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 66911.1719\n",
      "Epoch 10/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 58753.0312\n",
      "Epoch 11/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 51827.7422\n",
      "Epoch 12/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 45879.8789\n",
      "Epoch 13/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 40764.3398\n",
      "Epoch 14/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 36757.1797\n",
      "Epoch 15/200\n",
      "356/356 [==============================] - 47s 131ms/step - loss: 32838.4688\n",
      "Epoch 16/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 29705.4043\n",
      "Epoch 17/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 27115.8828\n",
      "Epoch 18/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 24820.9590\n",
      "Epoch 19/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 22888.1426\n",
      "Epoch 20/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 21290.8457\n",
      "Epoch 21/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 19817.3320\n",
      "Epoch 22/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 19149.4297\n",
      "Epoch 23/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 17473.5723\n",
      "Epoch 24/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 16320.3916\n",
      "Epoch 25/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 15941.3672\n",
      "Epoch 26/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 16051.9297\n",
      "Epoch 27/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 14253.0986\n",
      "Epoch 28/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 13558.9512\n",
      "Epoch 29/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 13465.0850\n",
      "Epoch 30/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 13189.1641\n",
      "Epoch 31/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12956.1816\n",
      "Epoch 32/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 13588.3936\n",
      "Epoch 33/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 13053.5156\n",
      "Epoch 34/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12169.1260\n",
      "Epoch 35/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 12586.4424\n",
      "Epoch 36/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11850.3203\n",
      "Epoch 37/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 14953.5371\n",
      "Epoch 38/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 16765.2617\n",
      "Epoch 39/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 15107.5137\n",
      "Epoch 40/200\n",
      "356/356 [==============================] - 56s 159ms/step - loss: 13256.5391\n",
      "Epoch 41/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 12852.3408\n",
      "Epoch 42/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11821.8828\n",
      "Epoch 43/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 12078.8877\n",
      "Epoch 44/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12071.6777\n",
      "Epoch 45/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12509.1719\n",
      "Epoch 46/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11694.8320\n",
      "Epoch 47/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11244.9512\n",
      "Epoch 48/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 10948.8975\n",
      "Epoch 49/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 11417.0664\n",
      "Epoch 50/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11054.5508\n",
      "Epoch 51/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 11350.6846\n",
      "Epoch 52/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 11285.8652\n",
      "Epoch 53/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10637.6562\n",
      "Epoch 54/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 10272.6318\n",
      "Epoch 55/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 11597.4551\n",
      "Epoch 56/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 10788.8828\n",
      "Epoch 57/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 11703.1260\n",
      "Epoch 58/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12958.3760\n",
      "Epoch 59/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 11781.0400\n",
      "Epoch 60/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 12455.0713\n",
      "Epoch 61/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 13105.2715\n",
      "Epoch 62/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11513.1572\n",
      "Epoch 63/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 11622.4238\n",
      "Epoch 64/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11627.5977\n",
      "Epoch 65/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10747.5986\n",
      "Epoch 66/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 10181.1641\n",
      "Epoch 67/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 10824.9707\n",
      "Epoch 68/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 9996.0723\n",
      "Epoch 69/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11052.9629\n",
      "Epoch 70/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11692.7979\n",
      "Epoch 71/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9949.7881\n",
      "Epoch 72/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10029.4092\n",
      "Epoch 73/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10808.1807\n",
      "Epoch 74/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10037.9072\n",
      "Epoch 75/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10573.7695\n",
      "Epoch 76/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 10469.1348\n",
      "Epoch 77/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11155.0781\n",
      "Epoch 78/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10735.7158\n",
      "Epoch 79/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9846.2998\n",
      "Epoch 80/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9733.8809\n",
      "Epoch 81/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 10075.7373\n",
      "Epoch 82/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9847.0752\n",
      "Epoch 83/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 12948.0986\n",
      "Epoch 84/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9729.4014\n",
      "Epoch 85/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9626.6367\n",
      "Epoch 86/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8793.1943\n",
      "Epoch 87/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8937.0840\n",
      "Epoch 88/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8924.4189\n",
      "Epoch 89/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8913.7939\n",
      "Epoch 90/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9034.8408\n",
      "Epoch 91/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9261.5703\n",
      "Epoch 92/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 45s 126ms/step - loss: 9637.1621\n",
      "Epoch 93/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 8676.3438\n",
      "Epoch 94/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8518.1006\n",
      "Epoch 95/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 9326.1582\n",
      "Epoch 96/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8451.1084\n",
      "Epoch 97/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 8227.8398\n",
      "Epoch 98/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8839.9912\n",
      "Epoch 99/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7744.8477\n",
      "Epoch 100/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 9048.1572\n",
      "Epoch 101/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 9067.8516\n",
      "Epoch 102/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 9876.6533\n",
      "Epoch 103/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8238.3086\n",
      "Epoch 104/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 8201.0361\n",
      "Epoch 105/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8107.1611\n",
      "Epoch 106/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7676.4473\n",
      "Epoch 107/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7690.4590\n",
      "Epoch 108/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8002.2900\n",
      "Epoch 109/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7808.7871\n",
      "Epoch 110/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7798.3706\n",
      "Epoch 111/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7993.1924\n",
      "Epoch 112/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8580.3887\n",
      "Epoch 113/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7778.1147\n",
      "Epoch 114/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7812.2241\n",
      "Epoch 115/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7432.4502\n",
      "Epoch 116/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8159.4922\n",
      "Epoch 117/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7910.8516\n",
      "Epoch 118/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 7746.9062\n",
      "Epoch 119/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8777.8555\n",
      "Epoch 120/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7986.4111\n",
      "Epoch 121/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7752.7617\n",
      "Epoch 122/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7467.5024\n",
      "Epoch 123/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7413.5459\n",
      "Epoch 124/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 9237.7520\n",
      "Epoch 125/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7433.4775\n",
      "Epoch 126/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7484.2178\n",
      "Epoch 127/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7944.9321\n",
      "Epoch 128/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7665.0205\n",
      "Epoch 129/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 8658.1367\n",
      "Epoch 130/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 8637.1602\n",
      "Epoch 131/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 9378.8818\n",
      "Epoch 132/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 14116.6572\n",
      "Epoch 133/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 10399.0381\n",
      "Epoch 134/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 8328.2158\n",
      "Epoch 135/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7865.6011\n",
      "Epoch 136/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7886.9902\n",
      "Epoch 137/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 8775.3096\n",
      "Epoch 138/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7955.0898\n",
      "Epoch 139/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7903.6660\n",
      "Epoch 140/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7305.7539\n",
      "Epoch 141/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7776.7773\n",
      "Epoch 142/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 8298.4473\n",
      "Epoch 143/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 7259.6118\n",
      "Epoch 144/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7616.4893\n",
      "Epoch 145/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7686.2612\n",
      "Epoch 146/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 6858.8394\n",
      "Epoch 147/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7069.9746\n",
      "Epoch 148/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 6929.2422\n",
      "Epoch 149/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7592.9062\n",
      "Epoch 150/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 12260.3066\n",
      "Epoch 151/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 8640.4639\n",
      "Epoch 152/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7754.2681\n",
      "Epoch 153/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7535.9248\n",
      "Epoch 154/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 7490.6040\n",
      "Epoch 155/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 8668.9951\n",
      "Epoch 156/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 7493.4312\n",
      "Epoch 157/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 6874.3926\n",
      "Epoch 158/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 6840.2739\n",
      "Epoch 159/200\n",
      "356/356 [==============================] - 45s 125ms/step - loss: 6622.7749\n",
      "Epoch 160/200\n",
      "356/356 [==============================] - 44s 125ms/step - loss: 6807.7559\n",
      "Epoch 161/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7266.0947\n",
      "Epoch 162/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7046.4121\n",
      "Epoch 163/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7513.5605\n",
      "Epoch 164/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7159.9614\n",
      "Epoch 165/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 8156.7671\n",
      "Epoch 166/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7670.9556\n",
      "Epoch 167/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8752.5830\n",
      "Epoch 168/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9280.7480\n",
      "Epoch 169/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 11264.2080\n",
      "Epoch 170/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8968.5957\n",
      "Epoch 171/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8556.9873\n",
      "Epoch 172/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7686.3833\n",
      "Epoch 173/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7140.7827\n",
      "Epoch 174/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7246.5264\n",
      "Epoch 175/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7563.4146\n",
      "Epoch 176/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6865.6973\n",
      "Epoch 177/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7294.0630\n",
      "Epoch 178/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6769.5225\n",
      "Epoch 179/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7014.1206\n",
      "Epoch 180/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7764.0483\n",
      "Epoch 181/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 6974.4824\n",
      "Epoch 182/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7056.7339\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 45s 126ms/step - loss: 6883.0146\n",
      "Epoch 184/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7098.5083\n",
      "Epoch 185/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7278.5972\n",
      "Epoch 186/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6828.8667\n",
      "Epoch 187/200\n",
      "356/356 [==============================] - 47s 133ms/step - loss: 6838.9404\n",
      "Epoch 188/200\n",
      "356/356 [==============================] - 47s 133ms/step - loss: 7105.0386\n",
      "Epoch 189/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 9076.1045\n",
      "Epoch 190/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7896.8159\n",
      "Epoch 191/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7746.0806\n",
      "Epoch 192/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7232.3154\n",
      "Epoch 193/200\n",
      "356/356 [==============================] - 47s 132ms/step - loss: 7309.6523\n",
      "Epoch 194/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7602.4722\n",
      "Epoch 195/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6797.6289\n",
      "Epoch 196/200\n",
      "223/356 [=================>............] - ETA: 17s - loss: 6433.5112"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0b20b9352d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2961/2961 [01:24<00:00, 35.03it/s]\n"
     ]
    }
   ],
   "source": [
    "to_split = np.array(dataset.iloc[14478:17486, ])\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)\n",
    "\n",
    "observations = []\n",
    "predictions = []\n",
    "\n",
    "test_len = len(X)\n",
    "for i in tqdm(range(test_len)):\n",
    "    \n",
    "    x = X[i].reshape((1, n_steps_in, n_features))\n",
    "    predicted = model.predict(x, verbose=0).flatten()\n",
    "    observed = y[i]\n",
    "    \n",
    "    observations.append(observed)\n",
    "    predictions.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nash_hor(horizon, observations, predictions):\n",
    "    \n",
    "    hor_pred = []\n",
    "    for pred in predictions:\n",
    "        hor_pred.append(pred[horizon-1])\n",
    "\n",
    "    hor_obs = []\n",
    "    for obs in observations:\n",
    "        hor_obs.append(obs[horizon-1])\n",
    "        \n",
    "    nash = get_nash(hor_obs, hor_pred)\n",
    "    plt.plot(hor_obs, label=\"obs\")\n",
    "    plt.plot(hor_pred, label=\"pred\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title('Forecasting horizon: '+str(horizon)+' hours (NSE: ' + f'{nash:.5f}' + ')')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_nash_hor(24,  observations, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"poc2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"poc2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([flow_df, et_df,rain_df], axis=1)\n",
    "dataset.columns = ['flow', 'et', 'rain']\n",
    "\n",
    "n_steps_in = 24\n",
    "n_steps_out = 24\n",
    "\n",
    "to_split = np.array(dataset.iloc[6078:17486, ])   # get 14086 to 17486 for testing\n",
    "X, y = split_sequences(to_split, n_steps_in, n_steps_out)\n",
    "\n",
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9101.9561\n",
      "Epoch 2/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 9679.5674\n",
      "Epoch 3/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8721.3447\n",
      "Epoch 4/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7622.4648\n",
      "Epoch 5/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7909.9683\n",
      "Epoch 6/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7176.2021\n",
      "Epoch 7/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7321.7407\n",
      "Epoch 8/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7229.8770\n",
      "Epoch 9/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7269.9707\n",
      "Epoch 10/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 6743.5796\n",
      "Epoch 11/200\n",
      "356/356 [==============================] - 45s 126ms/step - loss: 6741.2227\n",
      "Epoch 12/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7682.5088\n",
      "Epoch 13/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7015.2134\n",
      "Epoch 14/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 6383.4048\n",
      "Epoch 15/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6345.4585\n",
      "Epoch 16/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6026.4482\n",
      "Epoch 17/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 6860.6812\n",
      "Epoch 18/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 6904.4985\n",
      "Epoch 19/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6478.3179\n",
      "Epoch 20/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6856.6689\n",
      "Epoch 21/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 6950.2065\n",
      "Epoch 22/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7826.5098\n",
      "Epoch 23/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7343.7896\n",
      "Epoch 24/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7256.1035\n",
      "Epoch 25/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6535.6558\n",
      "Epoch 26/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6240.6050\n",
      "Epoch 27/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6671.9556\n",
      "Epoch 28/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6457.2266\n",
      "Epoch 29/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6789.4131\n",
      "Epoch 30/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6847.2148\n",
      "Epoch 31/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6592.3125\n",
      "Epoch 32/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6340.0728\n",
      "Epoch 33/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6435.4893\n",
      "Epoch 34/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6673.1279\n",
      "Epoch 35/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6536.4761\n",
      "Epoch 36/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6531.8794\n",
      "Epoch 37/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6400.5220\n",
      "Epoch 38/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6147.5850\n",
      "Epoch 39/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6492.6807\n",
      "Epoch 40/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7382.4473\n",
      "Epoch 41/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7206.2163\n",
      "Epoch 42/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 11189.4941\n",
      "Epoch 43/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8420.9355\n",
      "Epoch 44/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7753.0400\n",
      "Epoch 45/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7710.4771\n",
      "Epoch 46/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8579.3418\n",
      "Epoch 47/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8938.5254\n",
      "Epoch 48/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7488.0161\n",
      "Epoch 49/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7886.2222\n",
      "Epoch 50/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 18062.3438\n",
      "Epoch 51/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 16277.2393\n",
      "Epoch 52/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 13268.9766\n",
      "Epoch 53/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 12086.7979\n",
      "Epoch 54/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9945.7383\n",
      "Epoch 55/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 9777.8896\n",
      "Epoch 56/200\n",
      "356/356 [==============================] - 47s 132ms/step - loss: 8756.8828\n",
      "Epoch 57/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8236.4893\n",
      "Epoch 58/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8595.1514\n",
      "Epoch 59/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8418.7822\n",
      "Epoch 60/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8596.8799\n",
      "Epoch 61/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8587.8896\n",
      "Epoch 62/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8387.4639\n",
      "Epoch 63/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8105.6592\n",
      "Epoch 64/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8668.7695\n",
      "Epoch 65/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7275.2822\n",
      "Epoch 66/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 11723.4902\n",
      "Epoch 67/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8937.9727\n",
      "Epoch 68/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8227.6348\n",
      "Epoch 69/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8028.2856\n",
      "Epoch 70/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7595.5186\n",
      "Epoch 71/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8493.9082\n",
      "Epoch 72/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7277.8511\n",
      "Epoch 73/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7000.0332\n",
      "Epoch 74/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7921.1069\n",
      "Epoch 75/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7574.8408\n",
      "Epoch 76/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6836.8413\n",
      "Epoch 77/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6853.6641\n",
      "Epoch 78/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7003.7622\n",
      "Epoch 79/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6818.8823\n",
      "Epoch 80/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6654.7656\n",
      "Epoch 81/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7311.5107\n",
      "Epoch 82/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 8272.4150\n",
      "Epoch 83/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7144.3760\n",
      "Epoch 84/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7168.2378\n",
      "Epoch 85/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 8164.3740\n",
      "Epoch 86/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7909.0103\n",
      "Epoch 87/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 7338.7441\n",
      "Epoch 88/200\n",
      "356/356 [==============================] - 46s 130ms/step - loss: 6662.1387\n",
      "Epoch 89/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7540.4272\n",
      "Epoch 90/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6609.6592\n",
      "Epoch 91/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7213.0674\n",
      "Epoch 92/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 6859.3076\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356/356 [==============================] - 45s 128ms/step - loss: 7646.5566\n",
      "Epoch 94/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8679.3945\n",
      "Epoch 95/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 8051.0415\n",
      "Epoch 96/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7162.6362\n",
      "Epoch 97/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7288.8794\n",
      "Epoch 98/200\n",
      "356/356 [==============================] - 45s 127ms/step - loss: 7081.6772\n",
      "Epoch 99/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7200.6357\n",
      "Epoch 100/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7722.0068\n",
      "Epoch 101/200\n",
      "356/356 [==============================] - 45s 128ms/step - loss: 7497.5811\n",
      "Epoch 102/200\n",
      "356/356 [==============================] - 46s 129ms/step - loss: 7171.8271\n",
      "Epoch 103/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7158.8242\n",
      "Epoch 104/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7332.9248\n",
      "Epoch 105/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7929.1982\n",
      "Epoch 106/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 7011.4033\n",
      "Epoch 107/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 6788.0742\n",
      "Epoch 108/200\n",
      "356/356 [==============================] - 46s 128ms/step - loss: 8525.2793\n",
      "Epoch 109/200\n",
      "214/356 [=================>............] - ETA: 18s - loss: 6865.5308"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-0b20b9352d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
