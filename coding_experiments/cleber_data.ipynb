{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "flow_path = \"/home/colombelli/Documents/hydro-ml/data/Vazao.txt\"\n",
    "rain_path = \"/home/colombelli/Documents/hydro-ml/data/Chuva.txt\"\n",
    "et_path = \"/home/colombelli/Documents/hydro-ml/data/ET.txt\"\n",
    "\n",
    "flow_df = pd.read_csv(flow_path, sep=\"\\t\", header=None)\n",
    "flow_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"flow\"]\n",
    "\n",
    "rain_df = pd.read_csv(rain_path, sep=\"\\t\", header=None)\n",
    "rain_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"rain\"]\n",
    "\n",
    "et_df = pd.read_csv(et_path, sep=\"\\t\", header=None)\n",
    "et_df.columns = [\"day\", \"month\", \"year\", \"hour\", \"et\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series_for_window(start_date, end_date, station, dataframe):\n",
    "    return dataframe.loc[start_date:end_date, [station]]\n",
    "\n",
    "\n",
    "def check_nan_values(dataframe):\n",
    "    return dataframe.isnull().values.any()\n",
    "\n",
    "\n",
    "def get_valid_sequences(df):\n",
    "    valid_sequences = []\n",
    "    starting_idx = 0\n",
    "\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        flow = row[0]\n",
    "\n",
    "        if np.isnan(flow):\n",
    "\n",
    "            if starting_idx < i-1:\n",
    "                valid_sequences.append((starting_idx, i))\n",
    "                starting_idx = i+1\n",
    "            else:\n",
    "                starting_idx = i+1\n",
    "                continue\n",
    "    \n",
    "    if not check_nan_values(df.iloc[starting_idx:, :]):\n",
    "        valid_sequences.append((starting_idx, len(df)))\n",
    "    return valid_sequences\n",
    "\n",
    "\n",
    "def valid_seqs_minimum_len(valid_seqs, seq_len):\n",
    "    \n",
    "    valid_seqs_min_len = []\n",
    "    pops = []\n",
    "    for i, (start, end) in enumerate(valid_seqs):\n",
    "        if end - start >= seq_len:\n",
    "            valid_seqs_min_len.append((start, end))\n",
    "\n",
    "    return valid_seqs_min_len\n",
    "\n",
    "\n",
    "\n",
    "def split_sequences(possible_seqs, split_len):\n",
    "    \n",
    "    usable_seqs = []\n",
    "    for seq in possible_seqs:\n",
    "        usable_seqs += get_seq_splits(seq, split_len)\n",
    "        \n",
    "    return usable_seqs\n",
    "        \n",
    "        \n",
    "        \n",
    "def get_seq_splits(seq, split_len):\n",
    "    \n",
    "    start = seq[0]\n",
    "    end = seq[1]\n",
    "    \n",
    "    chunks = (end - start) // (split_len+1)     # +1 because there must be an unobserved item after each chunk\n",
    "                                                # which will be the y (after window value)\n",
    "\n",
    "    splits = []\n",
    "    prev_end_chunk = start\n",
    "    for i in range(chunks):\n",
    "\n",
    "        start_chunk = prev_end_chunk\n",
    "        end_chunk = start_chunk + split_len\n",
    "        splits.append((start_chunk, end_chunk))\n",
    "        prev_end_chunk = end_chunk+1\n",
    "        \n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_seq_obs_values(seq, df):\n",
    "    return np.array(df.iloc[seq[0]:seq[1], :]), np.array(df.iloc[seq[1], :])\n",
    "\n",
    "\n",
    "def split_seqs_train_test(train_frac, usable_seqs):\n",
    "    \n",
    "    total_seqs = len(usable_seqs)\n",
    "    train_amount = round(total_seqs * train_frac)\n",
    "    \n",
    "    random.shuffle(usable_seqs)\n",
    "    train_seqs = usable_seqs[0:train_amount]\n",
    "    test_seqs = usable_seqs[train_amount:]\n",
    "    \n",
    "    return train_seqs, test_seqs\n",
    "\n",
    "\n",
    "def mount_trainable_testable_arrays(seqs, df):\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for seq in seqs:\n",
    "        x, y = get_seq_obs_values(seq, df)\n",
    "        x_data.append(x)\n",
    "        y_data.append(y)\n",
    "    \n",
    "    return np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_cleb_df_into_wal_df(cleb_df):\n",
    "    \n",
    "    index_names = {}\n",
    "    for i, (_, row) in enumerate(cleb_df.iterrows()):\n",
    "        \n",
    "        year = str(int(row[2]))\n",
    "        month = str(int(row[1]))\n",
    "        day = str(int(row[0]))\n",
    "        hour = str(int(row[3]))\n",
    "        index_name = year+'-'+month+'-'+day+'-'+hour\n",
    "        \n",
    "        index_names[i] = index_name\n",
    "        \n",
    "    \n",
    "    cleb_df.rename(index=index_names)\n",
    "    cleb_df = cleb_df.drop('day', 1)\n",
    "    cleb_df = cleb_df.drop('month', 1)\n",
    "    cleb_df = cleb_df.drop('year', 1)\n",
    "    cleb_df = cleb_df.drop('hour', 1)\n",
    "    return cleb_df.replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_df = transform_cleb_df_into_wal_df(flow_df)\n",
    "rain_df = transform_cleb_df_into_wal_df(rain_df)\n",
    "et_df = transform_cleb_df_into_wal_df(et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_sequences = get_valid_sequences(flow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5953), (5962, 6051), (6069, 17486), (17487, 18718), (18741, 23437)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq = valid_seqs_minimum_len(valid_sequences, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5953), (5962, 6051), (6069, 17486), (17487, 18718), (18741, 23437)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_other_dfs_missing_values(val_seq, df):\n",
    "    \n",
    "    for seq in val_seq:\n",
    "        ini = seq[0]\n",
    "        end = seq[1]\n",
    "        \n",
    "        print(\"Seq:\", seq)\n",
    "        print(\"Missing?\", check_nan_values(df.iloc[ini:end, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq: (0, 5953)\n",
      "Missing? False\n",
      "Seq: (5962, 6051)\n",
      "Missing? False\n",
      "Seq: (6069, 17486)\n",
      "Missing? False\n",
      "Seq: (17487, 18718)\n",
      "Missing? False\n",
      "Seq: (18741, 23437)\n",
      "Missing? False\n"
     ]
    }
   ],
   "source": [
    "check_for_other_dfs_missing_values(val_seq, et_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq: (0, 5953)\n",
      "Missing? True\n",
      "Seq: (5962, 6051)\n",
      "Missing? False\n",
      "Seq: (6069, 17486)\n",
      "Missing? True\n",
      "Seq: (17487, 18718)\n",
      "Missing? False\n",
      "Seq: (18741, 23437)\n",
      "Missing? False\n"
     ]
    }
   ],
   "source": [
    "check_for_other_dfs_missing_values(val_seq, rain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 389),\n",
       " (390, 598),\n",
       " (599, 3000),\n",
       " (3391, 3930),\n",
       " (3931, 4386),\n",
       " (4387, 5646),\n",
       " (5647, 5953),\n",
       " (5962, 6077),\n",
       " (6078, 25954)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_seq_rain = get_valid_sequences(rain_df)\n",
    "valid_seq_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piece of code taken from: https://stackoverflow.com/questions/32480423/how-to-check-if-a-range-is-a-part-of-another-range-in-python-3-x\n",
    "def range_subset(range1, range2):\n",
    "    \"\"\"Whether range1 is a subset of range2.\"\"\"\n",
    "    if not range1:\n",
    "        return True  # empty range is subset of anything\n",
    "    if not range2:\n",
    "        return False  # non-empty range can't be subset of empty range\n",
    "    if len(range1) > 1 and range1.step % range2.step:\n",
    "        return False  # must have a single value or integer multiple step\n",
    "    return range1.start in range2 and range1[-1] in range2\n",
    "\n",
    "\n",
    "# not gonna use it now, but let it stay here to maybe future usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5953), (5962, 6051), (6069, 17486), (17487, 18718), (18741, 23437)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5953)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5962, 6051), (6069, 17486), (17487, 18718), (18741, 23437)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_seq[1] = (6078, 17486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5962, 6051), (6078, 17486), (17487, 18718), (18741, 23437)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq: (5962, 6051)\n",
      "Missing? False\n",
      "Seq: (6078, 17486)\n",
      "Missing? False\n",
      "Seq: (17487, 18718)\n",
      "Missing? False\n",
      "Seq: (18741, 23437)\n",
      "Missing? False\n"
     ]
    }
   ],
   "source": [
    "check_for_other_dfs_missing_values(val_seq, rain_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
